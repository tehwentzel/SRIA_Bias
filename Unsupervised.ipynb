{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5242e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d450bdf-5923-4b87-8b61-6133cd4d7491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.ndimage import rotate\n",
    "import Utils\n",
    "from Utils import Constants\n",
    "import cv2\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "from Models import *\n",
    "from DataLoaders import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb156980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_labels():\n",
    "    labels = ['train_data_clean.csv','validation_data_clean.csv']\n",
    "    dfs = [pd.read_csv(f) for f in labels]\n",
    "    df = pd.concat(dfs,axis=0).reset_index().drop('index',axis=1)\n",
    "    return df\n",
    "all_labels = get_all_labels()\n",
    "print(all_labels.shape[0]/100)\n",
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e6f6cd-7a43-48de-a6ac-747821eddb8c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UnsupervisedTripletEncoder(BaseModel):\n",
    "    #model to use as a triplet loss\n",
    "    #will tak in list of three image batchs\n",
    "    #returns list of tree embeedidng batchs + predictions on first batch of images\n",
    "    def __init__(self,\n",
    "                 base_model = None,\n",
    "                 feature_extractor = None,\n",
    "                 hidden_dims = [400],\n",
    "                 embedding_dropout=.3,\n",
    "                 base_name='model',\n",
    "                 fine_tune=False,\n",
    "                 **kwargs):\n",
    "        super(UnsupervisedTripletEncoder,self).__init__()\n",
    "                               \n",
    "        if base_model is None:\n",
    "            base_model = InceptionResnetV1(pretrained='vggface2')\n",
    "            base_name = 'dualfacenet'\n",
    "        else:\n",
    "            base_name = base_model.get_identifier()\n",
    "        \n",
    "        \n",
    "        if feature_extractor is None:\n",
    "            feature_extractor = InceptionResnetV1(pretrained='vggface2')\n",
    "        for param in feature_extractor.parameters():\n",
    "            param.requires_grad = fine_tune\n",
    "        for param in base_model.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        self.base_model = base_model\n",
    "        self.feature_extractor = feature_extractor\n",
    "        \n",
    "        self.embedding_dropout = torch.nn.Dropout(p=embedding_dropout)\n",
    "        curr_dim = base_model.logits.in_features + feature_extractor.logits.in_features\n",
    "        hidden_layers = []\n",
    "        \n",
    "        for i,size in enumerate(hidden_dims):\n",
    "            layer = torch.nn.Linear(curr_dim, size)\n",
    "            curr_dim = size\n",
    "            hidden_layers.append(layer)\n",
    "            hidden_layers.append(torch.nn.ReLU())\n",
    "            \n",
    "        self.hidden_layers = torch.nn.ModuleList(hidden_layers)\n",
    "        \n",
    "        self.embedding_size = hidden_dims[-1]\n",
    "        self.norm = torch.nn.BatchNorm1d(self.embedding_size)\n",
    "        \n",
    "        def add_dims(n,dims,prefix):\n",
    "            for dim in dims:\n",
    "                n += '_'+prefix+str(dim)\n",
    "            return n\n",
    "        \n",
    "        name_string = 'unsupervised_encoder_' + base_name\n",
    "        name_string = add_dims(name_string,hidden_dims,'h')\n",
    "        name_string += '_ed' + str(embedding_dropout).replace('0.','')\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        xb = self.base_model(x)\n",
    "        xf = self.feature_extractor(x)\n",
    "        x = torch.cat((xb,xf),axis=-1)\n",
    "        x = self.embedding_dropout(x)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        x = self.norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873e7eed-3932-4d8d-8130-85a738eb3a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial\n",
    "\n",
    "def get_embeddings(model,data_loader,device=None):\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    format_y = lambda y: y.long().to(device)\n",
    "    model.train(False)\n",
    "    embeddings = []\n",
    "    labels = [[],[],[]]\n",
    "    for i, [x_batch,y_batch] in enumerate(data_loader):\n",
    "        x_batch = x_batch.to(device)\n",
    "        embedding = model(x_batch)\n",
    "        embeddings.append(embedding.detach())\n",
    "        for ii,yy in enumerate(y_batch):\n",
    "            labels[ii].append(format_y(yy).detach())\n",
    "        print(i,end='\\r')\n",
    "    embeddings = torch.cat(embeddings).to(device)\n",
    "    labels = [torch.cat(l).to(device) for l in labels]\n",
    "    return embeddings, labels\n",
    "\n",
    "def cuda_mode(vector):\n",
    "    unique, counts = vector.unique(return_counts=True)\n",
    "    return unique[torch.argmax(counts)]\n",
    "\n",
    "def torch_knn(x, y, k=10):\n",
    "    #n x n distance matrix\n",
    "    dists = torch.cdist(x,x)\n",
    "    #indices for neighbors, self will always be first so skip it\n",
    "    neighbors = torch.argsort(dists,dim=1,descending=False)[:,1:k+1]\n",
    "    predictions = torch.zeros(y.shape).long()\n",
    "    y = y.long()\n",
    "    for i,n in enumerate(neighbors):\n",
    "        ny = y[n]\n",
    "        predictions[i] = cuda_mode(ny)\n",
    "    accuracy = torch.mean((y == predictions.to(y.get_device())).float()).item()\n",
    "    return predictions, accuracy\n",
    "\n",
    "def eval_knn_model(model,val_dataloader,klist=[5],device=None):\n",
    "    with torch.no_grad():\n",
    "        val_x, val_y = get_embeddings(model,val_dataloader,device=device)\n",
    "        results = []\n",
    "        for k in klist:\n",
    "            outputs = [torch_knn(val_x, vy,k=k) for vy in val_y]\n",
    "            accuracys = [i[1] for i in outputs]\n",
    "            results.append(accuracys)\n",
    "        if len(klist) < 2:\n",
    "            results = results[0]\n",
    "    return results\n",
    "\n",
    "# testmodel = UnsupervisedTripletEncoder()\n",
    "# testdata = UnsupervisedTripletGenerator(all_labels,Constants.data_root,upsample=False,batch_size=100,validation=True)\n",
    "# eval_knn_model(testmodel,testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5bca33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_train_history(model,history,root=''):\n",
    "    model_name = model.get_identifier()\n",
    "    \n",
    "    df = pd.DataFrame(history)\n",
    "    df['model'] = model_name\n",
    "    string = root + 'results/history_' + model_name + '.csv'\n",
    "    df.to_csv(string,index=False)\n",
    "    print('saved history to',string)\n",
    "    return df, string\n",
    "\n",
    "def train_model(model,\n",
    "                df,\n",
    "                root,\n",
    "                epochs=300,\n",
    "                lr=.001,\n",
    "                batch_size=200,\n",
    "                patience = 20,\n",
    "                save_path=None,\n",
    "                histogram =False,\n",
    "                upsample=True,\n",
    "                k_values=[3,5,7],\n",
    "                **kwargs,\n",
    "               ):\n",
    "    if save_path is None:\n",
    "        save_path = root + 'models/'+ model.get_identifier()\n",
    "        if upsample:\n",
    "            save_path += '_balanced'\n",
    "    if upsample:\n",
    "        patience = int(patience/5) + 1\n",
    "    data_loader = UnsupervisedTripletGenerator(df,Constants.data_root,batch_size=batch_size,upsample=False,**kwargs)\n",
    "    validation_loader = UnsupervisedTripletGenerator(df,Constants.data_root,batch_size=batch_size,upsample=False,validation=True,**kwargs)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.train(True)\n",
    "    \n",
    "    triplet_loss = torch.nn.TripletMarginLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    format_y = lambda y: y.long()#.to(device)\n",
    "    \n",
    "    def format_batch(inputs,grad=True):\n",
    "        xb = []\n",
    "        for xin in inputs:\n",
    "            xin = xin.to(device)\n",
    "            xin.requires_grad_(grad)\n",
    "            xb.append(xin)\n",
    "        return xb\n",
    "    \n",
    "    def embedding_step(m,xbatch): \n",
    "        base = m(xbatch[0])\n",
    "        positive = m(xbatch[1])\n",
    "        negative = m(xbatch[2])\n",
    "        loss = triplet_loss(base,positive,negative)\n",
    "        return base,loss\n",
    "    \n",
    "    def train_epoch():\n",
    "        running_loss = 0\n",
    "        running_accuracy = [0,0,0]\n",
    "        curr_loss = 0\n",
    "        count = 0\n",
    "        for i, [x_batch,y_batch] in enumerate(data_loader):\n",
    "            x_batch = format_batch(x_batch)\n",
    "            optimizer.zero_grad()\n",
    "            embedding,embedding_loss = embedding_step(model, x_batch)\n",
    "            embedding_loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += embedding_loss.item()\n",
    "            print('curr loss', embedding_loss.item(), 'step',i,' | ',end='\\r')\n",
    "            count += 1\n",
    "        return running_loss/count\n",
    "    \n",
    "    def val_epoch():\n",
    "        print('no validation nerd')\n",
    "    \n",
    "    best_val_loss = 100000\n",
    "    steps_since_improvement = 0\n",
    "    hist = []\n",
    "    best_weights = model.state_dict()\n",
    "    print('model being saved to',save_path)\n",
    "    for epoch in range(epochs):\n",
    "        print('epoch',epoch)\n",
    "        model.train(False)\n",
    "        val_accs = eval_knn_model(model,validation_loader,klist=k_values,device=device)\n",
    "        for kv, val_acc in zip(k_values,val_accs):\n",
    "            print('val accuracy k=',kv,val_acc)\n",
    "            \n",
    "        model.train(True)\n",
    "        avg_loss = train_epoch()\n",
    "        print('train loss', avg_loss)\n",
    "        #don't save immediately in case I cancel training\n",
    "        if best_val_loss > avg_loss and epoch > 1:\n",
    "            torch.save(model,save_path)\n",
    "            best_weights = model.state_dict()\n",
    "            best_val_loss = avg_loss\n",
    "            steps_since_improvement = 0\n",
    "        else:\n",
    "            steps_since_improvement += 1\n",
    "        \n",
    "        hist_entry = {\n",
    "            'epoch': epoch,\n",
    "            'train_loss': avg_loss,\n",
    "#             'train_acc':avg_acc,\n",
    "#             'val_loss':avg_loss,\n",
    "            'val_acc': val_accs,\n",
    "            'lr': lr,\n",
    "#             'loss_weights': '_'.join([str(l) for l in loss_weights])\n",
    "        }\n",
    "        hist.append(hist_entry)\n",
    "        save_train_history(model,hist,root=root)\n",
    "        if steps_since_improvement > patience:\n",
    "            break\n",
    "    return model,hist\n",
    "\n",
    "m,h = train_model(\n",
    "    UnsupervisedTripletEncoder(),\n",
    "    all_labels,\n",
    "    Constants.data_root,\n",
    "    batch_size=50,\n",
    "    histogram=False,\n",
    "    lr=.0001,\n",
    ")\n",
    "del m\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3470cf72-d79e-4449-8b77-340620ba6895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
