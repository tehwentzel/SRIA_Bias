{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5242e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d450bdf-5923-4b87-8b61-6133cd4d7491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.ndimage import rotate\n",
    "import Utils\n",
    "from Utils import Constants\n",
    "import cv2\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "from Models import *\n",
    "from DataLoaders import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb156980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>skin_tone</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>is_face</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN0001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN0002.png</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN0005.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN0007.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN0009.png</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8548</th>\n",
       "      <td>TRAIN11332.png</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8549</th>\n",
       "      <td>TRAIN2383.png</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8550</th>\n",
       "      <td>TRAIN6490.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8551</th>\n",
       "      <td>TRAIN9278.png</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8552</th>\n",
       "      <td>TRAIN8349.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8553 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                name  skin_tone  gender  age  is_face\n",
       "0      TRAIN0001.png          0       0    1    False\n",
       "1      TRAIN0002.png          5       1    0     True\n",
       "2      TRAIN0005.png          1       1    0    False\n",
       "3      TRAIN0007.png          1       0    1     True\n",
       "4      TRAIN0009.png          7       0    1    False\n",
       "...              ...        ...     ...  ...      ...\n",
       "8548  TRAIN11332.png          3       0    1    False\n",
       "8549   TRAIN2383.png          2       0    2    False\n",
       "8550   TRAIN6490.png          1       1    0     True\n",
       "8551   TRAIN9278.png          4       1    1     True\n",
       "8552   TRAIN8349.png          0       0    1     True\n",
       "\n",
       "[8553 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_all_labels():\n",
    "    labels = ['train_data_clean.csv','validation_data_clean.csv']\n",
    "    dfs = [pd.read_csv(f) for f in labels]\n",
    "    df = pd.concat(dfs,axis=0).reset_index().drop('index',axis=1)\n",
    "    return df\n",
    "all_labels = get_all_labels()\n",
    "print(all_labels.shape[0]/100)\n",
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02e6f6cd-7a43-48de-a6ac-747821eddb8c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UnsupervisedTripletEncoder(BaseModel):\n",
    "    #model to use as a triplet loss\n",
    "    #will tak in list of three image batchs\n",
    "    #returns list of tree embeedidng batchs + predictions on first batch of images\n",
    "    def __init__(self,\n",
    "                 base_model = None,\n",
    "                 feature_extractor = None,\n",
    "                 hidden_dims = [400],\n",
    "                 embedding_dropout=.3,\n",
    "                 base_name='model',\n",
    "                 fine_tune=False,\n",
    "                 **kwargs):\n",
    "        super(UnsupervisedTripletEncoder,self).__init__()\n",
    "                               \n",
    "        if base_model is None:\n",
    "            base_model = InceptionResnetV1(pretrained='vggface2')\n",
    "            base_name = 'dualfacenet'\n",
    "        else:\n",
    "            base_name = base_model.get_identifier()\n",
    "        \n",
    "        \n",
    "        if feature_extractor is None:\n",
    "            feature_extractor = InceptionResnetV1(pretrained='vggface2')\n",
    "        for param in feature_extractor.parameters():\n",
    "            param.requires_grad = fine_tune\n",
    "        for param in base_model.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        self.base_model = base_model\n",
    "        self.feature_extractor = feature_extractor\n",
    "        \n",
    "        self.embedding_dropout = torch.nn.Dropout(p=embedding_dropout)\n",
    "        curr_dim = base_model.logits.in_features + feature_extractor.logits.in_features\n",
    "        hidden_layers = []\n",
    "        \n",
    "        for i,size in enumerate(hidden_dims):\n",
    "            layer = torch.nn.Linear(curr_dim, size)\n",
    "            curr_dim = size\n",
    "            hidden_layers.append(layer)\n",
    "            hidden_layers.append(torch.nn.ReLU())\n",
    "            \n",
    "        self.hidden_layers = torch.nn.ModuleList(hidden_layers)\n",
    "        \n",
    "        self.embedding_size = hidden_dims[-1]\n",
    "        self.norm = torch.nn.BatchNorm1d(self.embedding_size)\n",
    "        \n",
    "        def add_dims(n,dims,prefix):\n",
    "            for dim in dims:\n",
    "                n += '_'+prefix+str(dim)\n",
    "            return n\n",
    "        \n",
    "        name_string = 'unsupervised_encoder_' + base_name\n",
    "        name_string = add_dims(name_string,hidden_dims,'h')\n",
    "        name_string += '_ed' + str(embedding_dropout).replace('0.','')\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        xb = self.base_model(x)\n",
    "        xf = self.feature_extractor(x)\n",
    "        x = torch.cat((xb,xf),axis=-1)\n",
    "        x = self.embedding_dropout(x)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        x = self.norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "873e7eed-3932-4d8d-8130-85a738eb3a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial\n",
    "\n",
    "def get_embeddings(model,data_loader,device=None):\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    format_y = lambda y: y.long().to(device)\n",
    "    model.train(False)\n",
    "    embeddings = []\n",
    "    labels = [[],[],[]]\n",
    "    for i, [x_batch,y_batch] in enumerate(data_loader):\n",
    "        x_batch = x_batch.to(device)\n",
    "        embedding = model(x_batch)\n",
    "        embeddings.append(embedding.detach())\n",
    "        for ii,yy in enumerate(y_batch):\n",
    "            labels[ii].append(format_y(yy).detach())\n",
    "        print(i,end='\\r')\n",
    "    embeddings = torch.cat(embeddings).to(device)\n",
    "    labels = [torch.cat(l).to(device) for l in labels]\n",
    "    return embeddings, labels\n",
    "\n",
    "def cuda_mode(vector):\n",
    "    unique, counts = vector.unique(return_counts=True)\n",
    "    return unique[torch.argmax(counts)]\n",
    "\n",
    "def torch_knn(x, y, k=10):\n",
    "    #n x n distance matrix\n",
    "    dists = torch.cdist(x,x)\n",
    "    #indices for neighbors, self will always be first so skip it\n",
    "    neighbors = torch.argsort(dists,dim=1,descending=False)[:,1:k+1]\n",
    "    predictions = torch.zeros(y.shape).long()\n",
    "    y = y.long()\n",
    "    for i,n in enumerate(neighbors):\n",
    "        ny = y[n]\n",
    "        predictions[i] = cuda_mode(ny)\n",
    "    accuracy = torch.mean((y == predictions.to(y.get_device())).float()).item()\n",
    "    return predictions, accuracy\n",
    "\n",
    "def eval_knn_model(model,val_dataloader,klist=[5],device=None):\n",
    "    with torch.no_grad():\n",
    "        val_x, val_y = get_embeddings(model,val_dataloader,device=device)\n",
    "        results = []\n",
    "        for k in klist:\n",
    "            outputs = [torch_knn(val_x, vy,k=k) for vy in val_y]\n",
    "            accuracys = [i[1] for i in outputs]\n",
    "            results.append(accuracys)\n",
    "        if len(klist) < 2:\n",
    "            results = results[0]\n",
    "    return results\n",
    "\n",
    "# testmodel = UnsupervisedTripletEncoder()\n",
    "# testdata = UnsupervisedTripletGenerator(all_labels,Constants.data_root,upsample=False,batch_size=100,validation=True)\n",
    "# eval_knn_model(testmodel,testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5bca33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model being saved to ../../data/models/abstractmodel_balanced\n",
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val accuracy k= 3 [0.2579796016216278, 0.5969069004058838, 0.8458374738693237]\n",
      "val accuracy k= 5 [0.2785455882549286, 0.6266864538192749, 0.8558736443519592]\n",
      "val accuracy k= 7 [0.2867719829082489, 0.6335965991020203, 0.8550510406494141]\n",
      "train loss 0.16926934211340158 step 876  |   \n",
      "saved history to ../../data/results/history_abstractmodel.csv\n",
      "epoch 1\n",
      "val accuracy k= 3 [0.23132610321044922, 0.5435999035835266, 0.7333004474639893]\n",
      "val accuracy k= 5 [0.2420204132795334, 0.5681145191192627, 0.7385653257369995]\n",
      "val accuracy k= 7 [0.24152682721614838, 0.577163577079773, 0.7382363080978394]\n",
      "train loss 0.0651183724499593step 877  |  |  \n",
      "saved history to ../../data/results/history_abstractmodel.csv\n",
      "epoch 2\n",
      "val accuracy k= 3 [0.2181638777256012, 0.5435999035835266, 0.7165186405181885]\n",
      "val accuracy k= 5 [0.23330043256282806, 0.5648239850997925, 0.7207963466644287]\n",
      "val accuracy k= 7 [0.24119776487350464, 0.576340913772583, 0.7219480276107788]\n",
      "curr loss 0.07191814482212067 step 563  |   \r"
     ]
    }
   ],
   "source": [
    "def save_train_history(model,history,root=''):\n",
    "    model_name = model.get_identifier()\n",
    "    \n",
    "    df = pd.DataFrame(history)\n",
    "    df['model'] = model_name\n",
    "    string = root + 'results/history_' + model_name + '.csv'\n",
    "    df.to_csv(string,index=False)\n",
    "    print('saved history to',string)\n",
    "    return df, string\n",
    "\n",
    "def train_model(model,\n",
    "                df,\n",
    "                root,\n",
    "                epochs=300,\n",
    "                lr=.001,\n",
    "                batch_size=200,\n",
    "                patience = 20,\n",
    "                save_path=None,\n",
    "                histogram =False,\n",
    "                upsample=True,\n",
    "                k_values=[3,5,7],\n",
    "                **kwargs,\n",
    "               ):\n",
    "    if save_path is None:\n",
    "        save_path = root + 'models/'+ model.get_identifier()\n",
    "        if upsample:\n",
    "            save_path += '_balanced'\n",
    "    if upsample:\n",
    "        patience = int(patience/5) + 1\n",
    "    data_loader = UnsupervisedTripletGenerator(df,Constants.data_root,batch_size=batch_size,upsample=False,**kwargs)\n",
    "    validation_loader = UnsupervisedTripletGenerator(df,Constants.data_root,batch_size=batch_size,upsample=False,validation=True,**kwargs)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.train(True)\n",
    "    \n",
    "    triplet_loss = torch.nn.TripletMarginLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    format_y = lambda y: y.long()#.to(device)\n",
    "    \n",
    "    def format_batch(inputs,grad=True):\n",
    "        xb = []\n",
    "        for xin in inputs:\n",
    "            xin = xin.to(device)\n",
    "            xin.requires_grad_(grad)\n",
    "            xb.append(xin)\n",
    "        return xb\n",
    "    \n",
    "    def embedding_step(m,xbatch): \n",
    "        base = m(xbatch[0])\n",
    "        positive = m(xbatch[1])\n",
    "        negative = m(xbatch[2])\n",
    "        loss = triplet_loss(base,positive,negative)\n",
    "        return base,loss\n",
    "    \n",
    "    def train_epoch():\n",
    "        running_loss = 0\n",
    "        running_accuracy = [0,0,0]\n",
    "        curr_loss = 0\n",
    "        count = 0\n",
    "        for i, [x_batch,y_batch] in enumerate(data_loader):\n",
    "            x_batch = format_batch(x_batch)\n",
    "            optimizer.zero_grad()\n",
    "            embedding,embedding_loss = embedding_step(model, x_batch)\n",
    "            embedding_loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += embedding_loss.item()\n",
    "            print('curr loss', embedding_loss.item(), 'step',i,' | ',end='\\r')\n",
    "            count += 1\n",
    "        return running_loss/count\n",
    "    \n",
    "    def val_epoch():\n",
    "        print('no validation nerd')\n",
    "    \n",
    "    best_val_loss = 100000\n",
    "    steps_since_improvement = 0\n",
    "    hist = []\n",
    "    best_weights = model.state_dict()\n",
    "    print('model being saved to',save_path)\n",
    "    for epoch in range(epochs):\n",
    "        print('epoch',epoch)\n",
    "        model.train(False)\n",
    "        val_accs = eval_knn_model(model,validation_loader,klist=k_values,device=device)\n",
    "        for kv, val_acc in zip(k_values,val_accs):\n",
    "            print('val accuracy k=',kv,val_acc)\n",
    "            \n",
    "        model.train(True)\n",
    "        avg_loss = train_epoch()\n",
    "        print('train loss', avg_loss)\n",
    "        #don't save immediately in case I cancel training\n",
    "        if best_val_loss > avg_loss and epoch > 1:\n",
    "            torch.save(model,save_path)\n",
    "            best_weights = model.state_dict()\n",
    "            best_val_loss = avg_loss\n",
    "            steps_since_improvement = 0\n",
    "        else:\n",
    "            steps_since_improvement += 1\n",
    "        \n",
    "        hist_entry = {\n",
    "            'epoch': epoch,\n",
    "            'train_loss': avg_loss,\n",
    "#             'train_acc':avg_acc,\n",
    "#             'val_loss':avg_loss,\n",
    "            'val_acc': val_accs,\n",
    "            'lr': lr,\n",
    "#             'loss_weights': '_'.join([str(l) for l in loss_weights])\n",
    "        }\n",
    "        hist.append(hist_entry)\n",
    "        save_train_history(model,hist,root=root)\n",
    "        if steps_since_improvement > patience:\n",
    "            break\n",
    "    return model,hist\n",
    "\n",
    "m,h = train_model(\n",
    "    UnsupervisedTripletEncoder(),\n",
    "    all_labels,\n",
    "    Constants.data_root,\n",
    "    batch_size=50,\n",
    "    histogram=False,\n",
    "    lr=.0001,\n",
    ")\n",
    "del m\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3470cf72-d79e-4449-8b77-340620ba6895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
