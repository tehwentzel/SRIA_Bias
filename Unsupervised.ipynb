{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5242e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d450bdf-5923-4b87-8b61-6133cd4d7491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.ndimage import rotate\n",
    "import Utils\n",
    "from Utils import Constants\n",
    "import cv2\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "from Models import *\n",
    "from DataLoaders import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb156980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>skin_tone</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>is_face</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN0001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN0002.png</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN0005.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN0007.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN0009.png</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11548</th>\n",
       "      <td>TEST2995.png</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11549</th>\n",
       "      <td>TEST2996.png</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11550</th>\n",
       "      <td>TEST2997.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11551</th>\n",
       "      <td>TEST2998.png</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11552</th>\n",
       "      <td>TEST2999.png</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11553 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                name  skin_tone  gender  age  is_face\n",
       "0      TRAIN0001.png          0       0    1    False\n",
       "1      TRAIN0002.png          5       1    0     True\n",
       "2      TRAIN0005.png          1       1    0    False\n",
       "3      TRAIN0007.png          1       0    1     True\n",
       "4      TRAIN0009.png          7       0    1    False\n",
       "...              ...        ...     ...  ...      ...\n",
       "11548   TEST2995.png          2       0    2     True\n",
       "11549   TEST2996.png          4       0    1     True\n",
       "11550   TEST2997.png          0       1    1     True\n",
       "11551   TEST2998.png          3       1    1     True\n",
       "11552   TEST2999.png          7       0    0     True\n",
       "\n",
       "[11553 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_all_labels():\n",
    "    labels = ['train_data_clean.csv','validation_data_clean.csv','test_data_clean.csv']\n",
    "    dfs = [pd.read_csv(f) for f in labels]\n",
    "    df = pd.concat(dfs,axis=0).reset_index().drop('index',axis=1)\n",
    "    return df\n",
    "all_labels = get_all_labels()\n",
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02e6f6cd-7a43-48de-a6ac-747821eddb8c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class UnsupervisedTripletEncoder(BaseModel):\n",
    "    #model to use as a triplet loss\n",
    "    #will tak in list of three image batchs\n",
    "    #returns list of tree embeedidng batchs + predictions on first batch of images\n",
    "    def __init__(self,\n",
    "                 base_model = None,\n",
    "                 feature_extractor = None,\n",
    "                 hidden_dims = [400],\n",
    "                 embedding_dropout=.3,\n",
    "                 base_name='model',\n",
    "                 fine_tune=False,\n",
    "                 **kwargs):\n",
    "        super(UnsupervisedTripletEncoder,self).__init__()\n",
    "                               \n",
    "        if base_model is None:\n",
    "            base_model = InceptionResnetV1(pretrained='vggface2')\n",
    "            base_name = 'dualfacenet'\n",
    "        else:\n",
    "            base_name = base_model.get_identifier()\n",
    "        \n",
    "        \n",
    "        if feature_extractor is None:\n",
    "            feature_extractor = InceptionResnetV1(pretrained='vggface2')\n",
    "        for param in feature_extractor.parameters():\n",
    "            param.requires_grad = fine_tune\n",
    "        for param in base_model.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        self.base_model = base_model\n",
    "        self.feature_extractor = feature_extractor\n",
    "        \n",
    "        self.embedding_dropout = torch.nn.Dropout(p=embedding_dropout)\n",
    "        curr_dim = base_model.logits.in_features + feature_extractor.logits.in_features\n",
    "        hidden_layers = []\n",
    "        \n",
    "        for i,size in enumerate(hidden_dims):\n",
    "            layer = torch.nn.Linear(curr_dim, size)\n",
    "            curr_dim = size\n",
    "            hidden_layers.append(layer)\n",
    "            hidden_layers.append(torch.nn.ReLU())\n",
    "            \n",
    "        self.hidden_layers = torch.nn.ModuleList(hidden_layers)\n",
    "        \n",
    "        self.embedding_size = hidden_dims[-1]\n",
    "        self.norm = torch.nn.BatchNorm1d(self.embedding_size)\n",
    "        \n",
    "        def add_dims(n,dims,prefix):\n",
    "            for dim in dims:\n",
    "                n += '_'+prefix+str(dim)\n",
    "            return n\n",
    "        \n",
    "        name_string = 'unsupervised_encoder_' + base_name\n",
    "        name_string = add_dims(name_string,hidden_dims,'h')\n",
    "        name_string += '_ed' + str(embedding_dropout).replace('0.','')\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        xb = self.base_model(x)\n",
    "        xf = self.feature_extractor(x)\n",
    "        x = torch.cat((xb,xf),axis=-1)\n",
    "        x = self.embedding_dropout(x)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        x = self.norm(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5bca33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model being saved to ../../data/models/abstractmodel_balanced\n",
      "epoch 0\n",
      "curr loss 0.2504828870296478 step 169  | | \r"
     ]
    }
   ],
   "source": [
    "def save_train_history(model,history,root=''):\n",
    "    model_name = model.get_identifier()\n",
    "    \n",
    "    df = pd.DataFrame(history)\n",
    "    df['model'] = model_name\n",
    "    string = root + 'results/history_' + model_name + '.csv'\n",
    "    df.to_csv(string,index=False)\n",
    "    print('saved history to',string)\n",
    "    return df, string\n",
    "\n",
    "def train_model(model,\n",
    "                df,\n",
    "                root,\n",
    "                epochs=300,\n",
    "                lr=.001,\n",
    "                batch_size=200,\n",
    "                patience = 20,\n",
    "                save_path=None,\n",
    "                histogram =False,\n",
    "                upsample=True,\n",
    "                **kwargs,\n",
    "               ):\n",
    "    if save_path is None:\n",
    "        save_path = root + 'models/'+ model.get_identifier()\n",
    "        if upsample:\n",
    "            save_path += '_balanced'\n",
    "    if upsample:\n",
    "        patience = int(patience/5) + 1\n",
    "    data_loader = UnsupervisedTripletGenerator(df,Constants.data_root,batch_size=batch_size,upsample=upsample,**kwargs)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.train(True)\n",
    "    \n",
    "    triplet_loss = torch.nn.TripletMarginLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    format_y = lambda y: y.long()#.to(device)\n",
    "    \n",
    "    def format_batch(inputs,grad=True):\n",
    "        xb = []\n",
    "        for xin in inputs:\n",
    "            xin = xin.to(device)\n",
    "            xin.requires_grad_(grad)\n",
    "            xb.append(xin)\n",
    "        return xb\n",
    "    \n",
    "    def embedding_step(m,xbatch): \n",
    "        base = m(xbatch[0])\n",
    "        positive = m(xbatch[1])\n",
    "        negative = m(xbatch[2])\n",
    "        loss = triplet_loss(base,positive,negative)\n",
    "        return base,loss\n",
    "    \n",
    "    def train_epoch():\n",
    "        running_loss = 0\n",
    "        running_accuracy = [0,0,0]\n",
    "        curr_loss = 0\n",
    "        count = 0\n",
    "        for i, [x_batch,y_batch] in enumerate(data_loader):\n",
    "            x_batch = format_batch(x_batch)\n",
    "            optimizer.zero_grad()\n",
    "            embedding,embedding_loss = embedding_step(model, x_batch)\n",
    "            embedding_loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += embedding_loss.item()\n",
    "            print('curr loss', embedding_loss.item(), 'step',i,' | ',end='\\r')\n",
    "            count += 1\n",
    "        return running_loss/count\n",
    "    \n",
    "    def val_epoch():\n",
    "        print('no validation nerd')\n",
    "    \n",
    "    best_val_loss = 100000\n",
    "    steps_since_improvement = 0\n",
    "    hist = []\n",
    "    best_weights = model.state_dict()\n",
    "    print('model being saved to',save_path)\n",
    "    for epoch in range(epochs):\n",
    "        print('epoch',epoch)\n",
    "        model.train(True)\n",
    "        avg_loss, avg_acc = train_epoch()\n",
    "        print('train loss', avg_loss, 'train accuracy', avg_acc)\n",
    "#         model.train(False)\n",
    "#         val_loss,val_embed_loss, val_acc = val_epoch()\n",
    "#         print('val loss', val_loss, 'val_embed_loss', val_embed_loss, 'val accuracy', val_acc)\n",
    "\n",
    "        #don't save immediately in case I cancel training\n",
    "        if best_val_loss > avg_loss and epoch > 1:\n",
    "            torch.save(model,save_path)\n",
    "            best_weights = model.state_dict()\n",
    "            best_val_loss = avg_loss\n",
    "            steps_since_improvement = 0\n",
    "        else:\n",
    "            steps_since_improvement += 1\n",
    "        \n",
    "        hist_entry = {\n",
    "            'epoch': epoch,\n",
    "            'train_loss': avg_loss,\n",
    "#             'train_acc':avg_acc,\n",
    "            'val_loss':avg_loss,\n",
    "#             'val_acc': val_acc,\n",
    "            'lr': lr,\n",
    "#             'loss_weights': '_'.join([str(l) for l in loss_weights])\n",
    "        }\n",
    "        hist.append(hist_entry)\n",
    "        save_train_history(model,hist,root=root)\n",
    "        if steps_since_improvement > patience:\n",
    "            break\n",
    "    return model,hist\n",
    "\n",
    "m,h = train_model(\n",
    "    UnsupervisedTripletEncoder(),\n",
    "    all_labels,\n",
    "    Constants.data_root,\n",
    "    batch_size=50,\n",
    "    histogram=False,\n",
    "    lr=.0001,\n",
    ")\n",
    "del m\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3470cf72-d79e-4449-8b77-340620ba6895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
