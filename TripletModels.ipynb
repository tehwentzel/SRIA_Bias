{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5242e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d450bdf-5923-4b87-8b61-6133cd4d7491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.ndimage import rotate\n",
    "import Utils\n",
    "from Utils import Constants\n",
    "import cv2\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "from Models import *\n",
    "from DataLoaders import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb156980",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv('train_data_augmented_balanceddualhistogram.csv')\n",
    "validation_labels = pd.read_csv('validation_data_augmented_balanceddualhistogram.csv')\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e6f6cd-7a43-48de-a6ac-747821eddb8c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TripletFacenetEncoder(BaseModel):\n",
    "    #model to use as a triplet loss\n",
    "    #will tak in list of three image batchs\n",
    "    #returns list of tree embeedidng batchs + predictions on first batch of images\n",
    "    def __init__(self,\n",
    "                 base_model = None,\n",
    "                 feature_extractor = None,\n",
    "                 hidden_dims = [400],\n",
    "                 embedding_dropout=.3,\n",
    "                 base_name='model',\n",
    "                 fine_tune=False,\n",
    "                 **kwargs):\n",
    "        super(TripletFacenetEncoder,self).__init__()\n",
    "                               \n",
    "        if base_model is None:\n",
    "            base_model = InceptionResnetV1(pretrained='vggface2')\n",
    "            base_name = 'dualfacenet'\n",
    "        else:\n",
    "            base_name = base_model.get_identifier()\n",
    "        \n",
    "        \n",
    "        if feature_extractor is None:\n",
    "            feature_extractor = InceptionResnetV1(pretrained='vggface2')\n",
    "        for param in feature_extractor.parameters():\n",
    "            param.requires_grad = fine_tune\n",
    "        for param in base_model.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        self.base_model = base_model\n",
    "        self.feature_extractor = feature_extractor\n",
    "        \n",
    "        self.embedding_dropout = torch.nn.Dropout(p=embedding_dropout)\n",
    "        curr_dim = base_model.logits.in_features + feature_extractor.logits.in_features\n",
    "        hidden_layers = []\n",
    "        \n",
    "        for i,size in enumerate(hidden_dims):\n",
    "            layer = torch.nn.Linear(curr_dim, size)\n",
    "            curr_dim = size\n",
    "            hidden_layers.append(layer)\n",
    "            hidden_layers.append(torch.nn.ReLU())\n",
    "            \n",
    "        self.hidden_layers = torch.nn.ModuleList(hidden_layers)\n",
    "        \n",
    "        self.embedding_size = hidden_dims[-1]\n",
    "        self.norm = torch.nn.BatchNorm1d(self.embedding_size)\n",
    "        \n",
    "        def add_dims(n,dims,prefix):\n",
    "            for dim in dims:\n",
    "                n += '_'+prefix+str(dim)\n",
    "            return n\n",
    "        \n",
    "        name_string = 'dualencoder_' + base_name\n",
    "        name_string = add_dims(name_string,hidden_dims,'h')\n",
    "        name_string += '_ed' + str(embedding_dropout).replace('0.','')\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        xb = self.base_model(x)\n",
    "        xf = self.feature_extractor(x)\n",
    "        x = torch.cat((xb,xf),axis=-1)\n",
    "        x = self.embedding_dropout(x)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        x = self.norm(x)\n",
    "        return x\n",
    "    \n",
    "class TripletFacenetClassifier(BaseModel):\n",
    "    #model to use as a triplet loss\n",
    "    #will tak in list of three image batchs\n",
    "    #returns list of tree embeedidng batchs + predictions on first batch of images\n",
    "    def __init__(self,\n",
    "                 input_dim,\n",
    "                 st_dims = [600],\n",
    "                 age_dims = [400],\n",
    "                 gender_dims = [400],\n",
    "                 st_dropout = .2,\n",
    "                 age_dropout = .2,\n",
    "                 gender_dropout = .2,\n",
    "                 **kwargs):\n",
    "        super(TripletFacenetClassifier,self).__init__()\n",
    "                               \n",
    "        self.st_layers = self.make_output(input_dim,st_dims,10,st_dropout)\n",
    "        self.age_layers = self.make_output(input_dim,age_dims,4,age_dropout)\n",
    "        self.gender_layers = self.make_output(input_dim,gender_dims,2,gender_dropout)\n",
    "        \n",
    "        def add_dims(n,dims,prefix):\n",
    "            for dim in dims:\n",
    "                n += '_'+prefix+str(dim)\n",
    "            return n\n",
    "        \n",
    "        name_string = 'triplet_decoder_'\n",
    "        name_string = add_dims(name_string,st_dims,'st')\n",
    "        \n",
    "        name_string = add_dims(name_string,age_dims,'a')\n",
    "        name_string = add_dims(name_string,gender_dims,'g')\n",
    "        name_string += '_std' + str(st_dropout).replace('0.','')\n",
    "        name_string += '_ad' + str(age_dropout).replace('0.','')\n",
    "        name_string += '_gd' + str(gender_dropout).replace('0.','')\n",
    "        self.name_string = name_string\n",
    "        \n",
    "    def embed(self,x):\n",
    "        x = self.base_model(x)\n",
    "        x = self.embedding_dropout(x)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x_st = self.apply_layers(x,self.st_layers)\n",
    "        x_age = self.apply_layers(x,self.age_layers)\n",
    "        x_gender = self.apply_layers(x,self.gender_layers)\n",
    "        return [x_st,x_age,x_gender]\n",
    "    \n",
    "class TripletModel(BaseModel):\n",
    "    \n",
    "    def __init__(self,encoder=None,decoder=None):\n",
    "        super(TripletModel,self).__init__()\n",
    "        if encoder is None:\n",
    "            encoder = TripletFacenetEncoder()\n",
    "        if decoder is None:\n",
    "            decoder = TripletFacenetClassifier(encoder.embedding_size)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.name_string = encoder.get_identifier() + decoder.get_identifier()\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "TripletModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5bca33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def categorical_accuracy(ypred,y):\n",
    "    #y is index, ypred i s one hot like in loss functions\n",
    "    predicted = torch.argmax(ypred,1).long()\n",
    "    correct = torch.mean((y.long() == predicted).float())\n",
    "    return correct\n",
    "\n",
    "def save_train_history(model,history,root=''):\n",
    "    model_name = model.get_identifier()\n",
    "    \n",
    "    df = pd.DataFrame(history)\n",
    "    df['model'] = model_name\n",
    "    string = root + 'results/history_' + model_name + '.csv'\n",
    "    df.to_csv(string,index=False)\n",
    "    print('saved history to',string)\n",
    "    return df, string\n",
    "\n",
    "def train_model(model,\n",
    "                train_df,\n",
    "                validation_df,\n",
    "                root,\n",
    "                epochs=300,\n",
    "                lr=.001,\n",
    "                batch_size=200,\n",
    "                patience = 20,\n",
    "                loss_weights = [2,1,.5],\n",
    "                save_path=None,\n",
    "                histogram =False,\n",
    "                upsample=True,\n",
    "                embedding_loss_weight = 1,\n",
    "                classification_loss_weight = 1,\n",
    "                **kwargs,\n",
    "               ):\n",
    "    if save_path is None:\n",
    "        save_path = root + 'models/'+ model.get_identifier()\n",
    "        if upsample:\n",
    "            save_path += '_balanced'\n",
    "    if upsample:\n",
    "        patience = int(patience/5) + 1\n",
    "    train_loader = TripletFaceGenerator(train_df,Constants.data_root,batch_size=batch_size,upsample=upsample,**kwargs)\n",
    "    validation_loader = TripletFaceGenerator(validation_df,Constants.data_root,validation=True,batch_size=batch_size,upsample=upsample,**kwargs)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.train(True)\n",
    "    \n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    triplet_loss = torch.nn.TripletMarginLoss()\n",
    "#     embedding_optimizer = torch.optim.Adam(model.encoder.parameters(), lr=lr)\n",
    "#     decoder_optimizer = torch.optim.Adam(model.decoder.parameters(), lr=lr)\n",
    "    optimizer = torch.optim.Adam(model.parameters(),lr=lr)\n",
    "    format_y = lambda y: y.long().to(device)\n",
    "    \n",
    "    def format_batch(inputs,grad=True):\n",
    "        xb = []\n",
    "        for xin in inputs:\n",
    "            xin = xin.to(device)\n",
    "            xin.requires_grad_(grad)\n",
    "            xb.append(xin)\n",
    "        return xb\n",
    "    \n",
    "    def embedding_step(m,xbatch): \n",
    "        base = m.encoder(xbatch[0])\n",
    "        positive = m.encoder(xbatch[1])\n",
    "        negative = m.encoder(xbatch[2])\n",
    "        loss = triplet_loss(base,positive,negative)\n",
    "        loss = torch.mul(loss,embedding_loss_weight)\n",
    "        return base,loss\n",
    "    \n",
    "    \n",
    "    def classifier_step(m,embedding,ytrue):\n",
    "        outputs = m.decoder(embedding)\n",
    "        losses = [loss_fn(ypred.float(),format_y(y)) for y,ypred in zip(ytrue,outputs)]\n",
    "        l1 = torch.mul(loss_weights[0],losses[0])\n",
    "        l2 =  torch.mul(loss_weights[1],losses[1])\n",
    "        l3 =  torch.mul(loss_weights[2],losses[2])\n",
    "        total_losses = l1 + l2 + l3\n",
    "        total_loss = torch.mul(total_losses,classification_loss_weight)\n",
    "        return outputs,total_losses\n",
    "        \n",
    "    def train_epoch():\n",
    "        running_loss = 0\n",
    "        running_embed_loss = 0\n",
    "        running_accuracy = [0,0,0]\n",
    "        curr_loss = 0\n",
    "        count = 0\n",
    "        for i, [x_batch, y_batch] in enumerate(train_loader):\n",
    "            x_batch = format_batch(x_batch)\n",
    "            optimizer.zero_grad()\n",
    "            embedding,embedding_loss = embedding_step(model, x_batch)\n",
    "            outputs, classification_loss = classifier_step(model,embedding,y_batch)\n",
    "            total_loss = classification_loss + embedding_loss\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += classification_loss.item()\n",
    "            running_embed_loss += embedding_loss.item()\n",
    "            print('curr loss class',classification_loss.item(),'embed', embedding_loss.item(), 'step',i,' | ',end='\\r')\n",
    "            count += 1\n",
    "            with torch.no_grad():\n",
    "                for i,(y,ypred) in enumerate(zip(y_batch,outputs)):\n",
    "                    accuracy = categorical_accuracy(ypred.float(),format_y(y))\n",
    "                    running_accuracy[i] += accuracy.item()\n",
    "        return running_loss/count,running_embed_loss/count, [a/count for a in running_accuracy]\n",
    "    \n",
    "    def val_epoch():\n",
    "        running_loss = 0\n",
    "        running_embed_loss = 0\n",
    "        running_accuracy = [0,0,0]\n",
    "        count = 0\n",
    "        with torch.no_grad():\n",
    "            for i, [x_batch, y_batch] in enumerate(validation_loader):\n",
    "                x_batch = format_batch(x_batch,grad=False)\n",
    "                embedding,embedding_loss = embedding_step(model, x_batch)\n",
    "                outputs, classification_loss = classifier_step(model,embedding,y_batch)\n",
    "                \n",
    "                running_loss += classification_loss.item()\n",
    "                running_embed_loss += embedding_loss.item()\n",
    "                count += 1\n",
    "                for i,(y,ypred) in enumerate(zip(y_batch, outputs)):\n",
    "                    accuracy = categorical_accuracy(ypred.float(),format_y(y))\n",
    "                    running_accuracy[i] += accuracy.item()\n",
    "        return running_loss/count,running_embed_loss/count, [a/count for a in running_accuracy]\n",
    "    \n",
    "    \n",
    "    best_val_loss = 100000\n",
    "    steps_since_improvement = 0\n",
    "    hist = []\n",
    "    best_weights = model.state_dict()\n",
    "    print('model being saved to',save_path)\n",
    "    for epoch in range(epochs):\n",
    "        print('epoch',epoch)\n",
    "        model.train(True)\n",
    "        avg_loss,avg_embed_loss, avg_acc = train_epoch()\n",
    "        print('train loss', avg_loss,'train embed loss',avg_embed_loss, 'train accuracy', avg_acc)\n",
    "        model.train(False)\n",
    "        val_loss,val_embed_loss, val_acc = val_epoch()\n",
    "        print('val loss', val_loss, 'val_embed_loss', val_embed_loss, 'val accuracy', val_acc)\n",
    "        #don't save immediately in case I cancel training\n",
    "        if best_val_loss > val_loss and epoch > 1:\n",
    "            torch.save(model,save_path)\n",
    "            best_weights = model.state_dict()\n",
    "            best_val_loss = val_loss\n",
    "            steps_since_improvement = 0\n",
    "        else:\n",
    "            steps_since_improvement += 1\n",
    "        \n",
    "        hist_entry = {\n",
    "            'epoch': epoch,\n",
    "            'train_loss': avg_loss,\n",
    "            'train_acc':avg_acc,\n",
    "            'val_loss':val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'lr': lr,\n",
    "            'loss_weights': '_'.join([str(l) for l in loss_weights])\n",
    "        }\n",
    "        hist.append(hist_entry)\n",
    "        save_train_history(model,hist,root=root)\n",
    "        if steps_since_improvement > patience:\n",
    "            break\n",
    "    return model,hist\n",
    "\n",
    "m,h = train_model(\n",
    "    TripletModel(),\n",
    "    train_labels,\n",
    "    validation_labels,\n",
    "    Constants.data_root,\n",
    "    batch_size=50,\n",
    "    histogram=False,\n",
    "    lr=.0001,\n",
    ")\n",
    "del m\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3470cf72-d79e-4449-8b77-340620ba6895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
