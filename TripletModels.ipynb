{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5242e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d450bdf-5923-4b87-8b61-6133cd4d7491",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (DataLoaders.py, line 299)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/opt/conda/envs/rapids/lib/python3.8/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3331\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-6a2e10bb53b6>\"\u001b[0;36m, line \u001b[0;32m12\u001b[0;36m, in \u001b[0;35m<module>\u001b[0;36m\u001b[0m\n\u001b[0;31m    from DataLoaders import *\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"/workspace/SRIA_Bias/DataLoaders.py\"\u001b[0;36m, line \u001b[0;32m299\u001b[0m\n\u001b[0;31m    output = [[baseimage,anchorimage,biasimage] labels]\u001b[0m\n\u001b[0m                                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.ndimage import rotate\n",
    "import Utils\n",
    "from Utils import Constants\n",
    "import cv2\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "from Models import *\n",
    "from DataLoaders import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb156980",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv('train_data_augmented_balanceddualhistogram.csv')\n",
    "validation_labels = pd.read_csv('validation_data_augmented_balanceddualhistogram.csv')\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e6f6cd-7a43-48de-a6ac-747821eddb8c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TripletFacenetModel(FacenetModel):\n",
    "    #model to use as a triplet loss\n",
    "    #will tak in list of three image batchs\n",
    "    #returns list of tree embeedidng batchs + predictions on first batch of images\n",
    "    def __init__(self,**kwargs):\n",
    "        super(TripletFacenetModel,self).__init__(**kwargs)\n",
    "                               \n",
    "        self.name_string = 'triplet_' + self.name_string\n",
    "    \n",
    "    def embed(self,x):\n",
    "        x = self.base_model(x)\n",
    "        x = self.embedding_dropout(x)\n",
    "        for layer in self.hidden_layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "        \n",
    "    def forward(self,x):\n",
    "        [xx,anchor,bias] = x\n",
    "        xx = self.embed(xx)\n",
    "        anchor = self.embed(anchor)\n",
    "        bias = self.embed(bias)\n",
    "        \n",
    "        x_st = self.apply_layers(xx,self.st_layers)\n",
    "        x_age = self.apply_layers(xx,self.age_layers)\n",
    "        x_gender = self.apply_layers(xx,self.gender_layers)\n",
    "        return [xx,anchor,bias], [x_st,x_age,x_gender]\n",
    "    \n",
    "TripletFacenetModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5bca33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def categorical_accuracy(ypred,y):\n",
    "    #y is index, ypred i s one hot like in loss functions\n",
    "    predicted = torch.argmax(ypred,1).long()\n",
    "    correct = torch.mean((y.long() == predicted).float())\n",
    "    return correct\n",
    "\n",
    "def save_train_history(model,history,root=''):\n",
    "    model_name = model.get_identifier()\n",
    "    \n",
    "    df = pd.DataFrame(history)\n",
    "    df['model'] = model_name\n",
    "    string = root + 'results/history_' + model_name + '.csv'\n",
    "    df.to_csv(string,index=False)\n",
    "    print('saved history to',string)\n",
    "    return df, string\n",
    "\n",
    "def train_model(model,\n",
    "                train_df,\n",
    "                validation_df,\n",
    "                root,\n",
    "                epochs=300,\n",
    "                lr=.001,\n",
    "                batch_size=200,\n",
    "                patience = 20,\n",
    "                loss_weights = [2,1,.5],\n",
    "                save_path=None,\n",
    "                histogram =False,\n",
    "                upsample=True,\n",
    "                embedding_loss_weight = 1,\n",
    "                classification_loss_weight = 1,\n",
    "                **kwargs,\n",
    "               ):\n",
    "    if save_path is None:\n",
    "        save_path = root + 'models/'+ model.get_identifier()\n",
    "        if upsample:\n",
    "            save_path += '_balanced'\n",
    "    if upsample:\n",
    "        patience = int(patience/5) + 1\n",
    "    train_loader = TripletFaceGenerator(train_df,Constants.data_root,batch_size=batch_size,upsample=upsample,**kwargs)\n",
    "    validation_loader = TripletFaceGenerator(validation_df,Constants.data_root,validation=True,batch_size=batch_size,upsample=upsample,**kwargs)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.train(True)\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    triplet_loss = torch.nn.TripletMarginLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    format_y = lambda y: y.long().to(device)\n",
    "    def format_batch(inputs,grad=True):\n",
    "        xb = []\n",
    "        for xin in inputs:\n",
    "            xin = xin.to(device)\n",
    "            xin.requires_grad_(grad)\n",
    "            xb.append(xin)\n",
    "        return xb\n",
    "    \n",
    "    def get_classification_loss(outputs,ytrue):\n",
    "        losses = [loss_fn(ypred.float(),format_y(y)) for y,ypred in zip(ytrue,outputs)]\n",
    "        l1 = torch.mul(loss_weights[0],losses[0])\n",
    "        l2 =  torch.mul(loss_weights[1],losses[1])\n",
    "        l3 =  torch.mul(loss_weights[2],losses[2])\n",
    "        total_losses = l1 + l2 + l3\n",
    "        return total_losses\n",
    "\n",
    "    def get_loss(m,xbatch,ybatch):\n",
    "        ouputs = m(format_batch(xbatch))\n",
    "        [e,ep,en,prediction] = outputs\n",
    "        embed_loss = triplet_loss(e,ep,en)\n",
    "        closs = classification_loss(prediction,ybatch)\n",
    "        loss = torch.mul(closs,classificaton_loss_weight) + torch.mul(embed_loss,embedding_loss_weight)\n",
    "        return prediction,loss\n",
    "        \n",
    "    def train_epoch():\n",
    "        running_loss = 0\n",
    "        running_accuracy = [0,0,0]\n",
    "        curr_loss = 0\n",
    "        count = 0\n",
    "        for i, [x_batch, y_batch] in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            outputs,total_losses = get_loss(model, x_batch,y_batch)\n",
    "            total_losses.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += total_losses.item()\n",
    "            print('curr loss',total_losses.item(), 'step',i,' | ',end='\\r')\n",
    "            count += 1\n",
    "            with torch.no_grad():\n",
    "                for i,(y,ypred) in enumerate(zip(y_batch,outputs)):\n",
    "                    accuracy = categorical_accuracy(ypred.float(),format_y(y))\n",
    "                    running_accuracy[i] += accuracy.item()\n",
    "        return running_loss/count, [a/count for a in running_accuracy]\n",
    "    \n",
    "    def val_epoch():\n",
    "        running_loss = 0\n",
    "        running_accuracy = [0,0,0]\n",
    "        count = 0\n",
    "        for i, [x_batch, y_batch] in enumerate(validation_loader):\n",
    "            outputs,total_losses = get_loss(model,x_batch,y_batch)\n",
    "            running_loss += total_losses.item()\n",
    "            count += 1\n",
    "            for i,(y,ypred) in enumerate(zip(y_batch, outputs)):\n",
    "                accuracy = categorical_accuracy(ypred.float(),format_y(y))\n",
    "                running_accuracy[i] += accuracy.item()\n",
    "        return running_loss/count, [a/count for a in running_accuracy]\n",
    "    \n",
    "    \n",
    "    best_val_loss = 100000\n",
    "    steps_since_improvement = 0\n",
    "    hist = []\n",
    "    best_weights = model.state_dict()\n",
    "    print('model being saved to',save_path)\n",
    "    for epoch in range(epochs):\n",
    "        print('epoch',epoch)\n",
    "        model.train(True)\n",
    "        avg_loss, avg_acc = train_epoch()\n",
    "        print('train loss', avg_loss, 'train accuracy', avg_acc)\n",
    "        model.train(False)\n",
    "        val_loss, val_acc = val_epoch()\n",
    "        print('val loss', val_loss, 'val accuracy', val_acc)\n",
    "        if best_val_loss > val_loss:\n",
    "            torch.save(model,save_path)\n",
    "            best_weights = model.state_dict()\n",
    "            best_val_loss = val_loss\n",
    "            steps_since_improvement = 0\n",
    "        else:\n",
    "            steps_since_improvement += 1\n",
    "        \n",
    "        hist_entry = {\n",
    "            'epoch': epoch,\n",
    "            'train_loss': avg_loss,\n",
    "            'train_acc':avg_acc,\n",
    "            'val_loss':val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'lr': lr,\n",
    "            'loss_weights': '_'.join([str(l) for l in loss_weights])\n",
    "        }\n",
    "        hist.append(hist_entry)\n",
    "        save_train_history(model,hist,root=root)\n",
    "        if steps_since_improvement > patience:\n",
    "            break\n",
    "    return model,hist\n",
    "\n",
    "m,h = train_model(\n",
    "    TripletFacenetModel(),\n",
    "    train_labels,\n",
    "    validation_labels,\n",
    "    Constants.data_root,\n",
    "    batch_size=100,\n",
    "    histogram=False,\n",
    "    lr=.0001,\n",
    ")\n",
    "del m\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3470cf72-d79e-4449-8b77-340620ba6895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
