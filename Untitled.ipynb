{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb78f954-5c5d-4051-a47e-3dc8f8b3c267",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.ndimage import rotate\n",
    "import Utils\n",
    "from Utils import Constants\n",
    "import cv2\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "from Models import *\n",
    "from DataLoaders import *\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score, precision_score, recall_score, roc_auc_score, average_precision_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a53650-82fa-4c96-921a-20a07d94feef",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model(file):\n",
    "    model = torch.load(Constants.model_folder + file).to(torch.device('cpu'))\n",
    "    model.load_state_dict(torch.load(Constants.model_folder + file + '_states'))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def eval_labels(model,labels,use_histogram=False,filter_nonfaces=False,**kwargs):\n",
    "    device = torch.device('cpu')\n",
    "    names = Constants.labels[:]\n",
    "    model = model.to(device)\n",
    "    if filter_nonfaces:\n",
    "        labels = labels[labels.is_face]\n",
    "    dataset = FaceGenerator(labels,Constants.data_root,upsample=False,validation=True,shuffle_on_init=False,random_upsample=False,filter_nonfaces=filter_nonfaces,**kwargs)\n",
    "    print(labels.shape[0],len(dataset))\n",
    "    predicted = [[],[],[]]\n",
    "    actual = [[],[],[]]\n",
    "    with torch.no_grad():\n",
    "        for i,[xbatch, ybatch] in enumerate(dataset):\n",
    "            if use_histogram:\n",
    "                xb = add_batch_histogram(xbatch,device=device,grad=False)\n",
    "            else:\n",
    "                xb = xbatch.to(device)\n",
    "            ypreds = model(xb)\n",
    "            for ii,(ytrue,ypred) in enumerate(zip(ybatch,ypreds)):\n",
    "                predicted[ii].append(ypred.detach().numpy())\n",
    "                actual[ii].append(ytrue.detach().numpy())\n",
    "    for i in range(len(predicted)):\n",
    "        predicted[i] = np.concatenate(predicted[i],axis=0)\n",
    "        actual[i] = np.concatenate(actual[i],axis=0)\n",
    "    return actual, predicted\n",
    "\n",
    "def subclass_predictions(ytrue,ypred):\n",
    "    yt = np.stack(ytrue,axis=-1).T\n",
    "    yp = np.stack([np.argmax(yyp,axis=-1) for yyp in ypred])\n",
    "    yp_prob = np.stack([np.amax(yyp,axis=-1) for yyp in ypred])\n",
    "    groupstring = lambda x: '-'.join([str(i) for i in x])\n",
    "    group_p = np.apply_along_axis(groupstring, 0, yp)\n",
    "    group_t = np.apply_along_axis(groupstring, 0, yt)\n",
    "    return group_t, group_p, yp_prob\n",
    "\n",
    "def subgroup_results(y,predicted):\n",
    "    entry = {\n",
    "        'accuracy': accuracy_score(y,predicted),\n",
    "        'f1': f1_score(y,predicted),\n",
    "        'precision': precision_score(y,predicted,zero_division=0),\n",
    "        'recall': recall_score(y,predicted),\n",
    "    }\n",
    "    return entry\n",
    "    \n",
    "def multiclass_metrics(y,ypred,labels=None):\n",
    "    squeeze = lambda yy: np.argmax(yy,axis=1) if yy.ndim > 1 else yy\n",
    "    res = {}\n",
    "    if labels is None:\n",
    "        labels = Constants.labels[:]\n",
    "    for yy, yypred, label in zip(y,ypred,labels):\n",
    "        yypred = squeeze(yypred)\n",
    "        entry = {\n",
    "            'accuracy': accuracy_score(yy,yypred),\n",
    "#             'f1_micro': f1_score(yy,yypred,average='micro'),\n",
    "            'f1': f1_score(yy,yypred,average='macro'),\n",
    "            'precision': precision_score(yy,yypred,average='macro'),\n",
    "            'recall': balanced_accuracy_score(yy,yypred),\n",
    "        }\n",
    "        res[label] = entry\n",
    "    return pd.DataFrame(res)\n",
    "\n",
    "def get_classwise_metrics(ylist,ypredlist):\n",
    "    labels = Constants.labels[:]\n",
    "    results = {}\n",
    "    ygroup, ygroup_pred,_ = subclass_predictions(ylist,ypredlist)\n",
    "    ylist = ylist + [ygroup]\n",
    "    ypredlist = ypredlist + [ygroup_pred]\n",
    "    labels = labels + ['subgroup']\n",
    "    getmax = lambda res,key: np.max([v[key] for k,v in res.items() if key != 'multiclass'])\n",
    "    getmin = lambda res,key: np.min([v[key] for k,v in res.items() if key != 'multiclass'])\n",
    "    global_results = multiclass_metrics(ylist,ypredlist,labels)\n",
    "    for i, name in enumerate(labels):\n",
    "        y = ylist[i]\n",
    "        ypred = ypredlist[i]\n",
    "        classes = np.unique(y)\n",
    "        class_entry = {}\n",
    "        for c in classes:\n",
    "            yset = (y == c).astype(int)\n",
    "            if ypred.ndim > 1:\n",
    "                yp = (np.argmax(ypred,axis=1) == c).astype(int)\n",
    "            else:\n",
    "                yp = (ypred == c).astype(int)\n",
    "            vals = subgroup_results(yset,yp)\n",
    "            class_entry[c] = vals\n",
    "        extents = {}\n",
    "        for key in class_entry[classes[0]].keys():\n",
    "            maxval = getmax(class_entry,key)\n",
    "            minval = getmin(class_entry,key)\n",
    "            extents[key] = maxval - minval\n",
    "        class_entry['differential'] = extents\n",
    "        class_entry['multiclass'] = global_results.get(name,{'accuracy':0,'f1':0,'precision':0,'recall':0})\n",
    "        results[name] = pd.DataFrame(class_entry)\n",
    "    return results\n",
    "\n",
    "def plot_confusion_matrices(y,ypred):\n",
    "    ygroup, ygroup_pred ,_ = subclass_predictions(y,ypred)\n",
    "    y = y + [ygroup]\n",
    "    ypred = ypred + [ygroup_pred]\n",
    "    \n",
    "    fig, axes = plt.subplots(len(y),1,\n",
    "                             figsize=(10,45),\n",
    "                             gridspec_kw = {'height_ratios':[1,1,1,3]}\n",
    "                            )\n",
    "    titles = Constants.labels[:] + ['subgroup']\n",
    "    cms = []\n",
    "    for i in range(len(y)):\n",
    "        if ypred[i].ndim > 1:\n",
    "            yp = np.argmax(ypred[i],axis=1)\n",
    "        else:\n",
    "            yp = ypred[i]\n",
    "        sublabels = sorted(set(np.unique(y[i])).union(set(np.unique(yp))))\n",
    "        cm = confusion_matrix(y[i],yp,labels=sublabels)\n",
    "        Utils.ConfusionMatrixDisplay.from_predictions(y[i],ypred[i],\n",
    "                                                      ax=axes[i],\n",
    "                                                      normalize='true',\n",
    "                                                      colorbar=False,\n",
    "                                                      display_labels=sublabels,\n",
    "                                                      include_values = (i < 3),\n",
    "                                                      title=titles[i])\n",
    "        cms.append(cm)\n",
    "    return\n",
    "\n",
    "def plot_results(results):\n",
    "    fig, axes = plt.subplots(4,1,\n",
    "                             figsize=(10,40),\n",
    "                             gridspec_kw = {'height_ratios':[5,2,1,35]}\n",
    "                            )\n",
    "    for i,(k,v) in enumerate(results.items()):\n",
    "        a = sns.heatmap(\n",
    "            v.T,\n",
    "            ax=axes[i],\n",
    "            cmap='Greens',\n",
    "            annot=True,\n",
    "            vmin=0,\n",
    "            vmax=1,\n",
    "            cbar=False,\n",
    "        )\n",
    "        a.xaxis.tick_top()\n",
    "        a.set_title(k)\n",
    "    return\n",
    "\n",
    "def resultify(y,ypred):\n",
    "    res = get_classwise_metrics(y,ypred)\n",
    "    plot_confusion_matrices(y,ypred)\n",
    "    plot_results(res)\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d038a857-af68-4663-a8d5-47ed185c0f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv('train_data_clean.csv')\n",
    "val_labels = pd.read_csv('validation_data_clean.csv')\n",
    "test_labels = pd.read_csv('test_data_clean.csv')\n",
    "test_labels.shape, train_labels.shape, val_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b89665-9d40-4194-ac44-bd5fe3fc1d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code for getting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8209e7ed-314d-409b-a858-d101dbdd8179",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('train_data_augmented_balanceddualhistogram.csv').shape, pd.read_csv('validation_data_augmented_balanceddualhistogram.csv').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a688567b-3724-4b68-9655-319949d16f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dualfacenet + histogram\n",
    "# file = 'dual_dualfacenet_h400_st600_a400_g400_ed3_std2_ad2_gd2_hist10_histd_0.1_balanced'\n",
    "\n",
    "# #dual facenet\n",
    "# file = 'dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2'\n",
    "\n",
    "#triplet model\n",
    "# file='abstractmodeltriplet_decoder__st600_a400_g400_std2_ad2_gd2_balanced'\n",
    "\n",
    "file = 'abstractmodeltriplet_decoder__st600_a400_g400_std2_ad2_gd2_rbalanced'\n",
    "\n",
    "model = get_model(file)\n",
    "y,ypred = eval_labels(model, test_labels,use_histogram=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a46840-d9e9-4e04-ae74-1697d2a475d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def disparity_score(ytrue, ypred):\n",
    "    cm = confusion_matrix(ytrue,ypred)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    all_acc = list(cm.diagonal())\n",
    "    return max(all_acc) - min(all_acc)\n",
    "\n",
    "\n",
    "def calc_scores(y,ypred):\n",
    "    ypred = [np.argmax(yy,axis=1) for yy in ypred]\n",
    "    acc ={}\n",
    "    disp = {}\n",
    "    for yy, yp, name in zip(y,ypred,Constants.labels[:]):\n",
    "        acc[name] = accuracy_score(yy,yp)\n",
    "        disp[name] = disparity_score(yy,yp)\n",
    "    return {'accuracy': acc,'disparity': disp}\n",
    "\n",
    "def get_score(y,ypred):\n",
    "    results = calc_scores(y,ypred)\n",
    "    acc = results['accuracy']\n",
    "    disp = results['disparity']\n",
    "    ad = 2*acc['gender']*(1-disp['gender']) + 4*acc['age']*(1-disp['age']**2) + 10*acc['skin_tone']*(1-disp['skin_tone']**5)\n",
    "    \n",
    "    res = {\n",
    "        'submission_name': 'placeholder',\n",
    "        'score': ad,\n",
    "        'metrics': results\n",
    "    }\n",
    "    return res\n",
    "\n",
    "get_score(y,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6425ed7-e423-4eec-bcc7-9e180db4f710",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultify(y,ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd6add43-5553-4b25-a83d-36948bb51eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_history(modelfile):\n",
    "    #I messed up in logging this but it shoud always be balanced, bascially\n",
    "    modelfile = modelfile.replace('_balanced','')\n",
    "    hist = pd.read_csv(Constants.result_folder+'history_' + modelfile+'.csv')\n",
    "    return hist\n",
    "\n",
    "def plot_history(file,ax=None):\n",
    "    history = get_history(file)\n",
    "    train_loss = history.train_loss.values\n",
    "    val_loss = history.val_loss.values\n",
    "    x = [i for i,k in enumerate(train_loss)]\n",
    "    if ax is None:\n",
    "        fig,ax = plt.subplots(1,1,figsize=(5,5))\n",
    "    ax.plot(x,train_loss,c='b')\n",
    "    ax.plot(x,val_loss,c='r')\n",
    "    ax.set_title('Training history')\n",
    "    ax.set_xlabel('epoch')\n",
    "    ax.set_ylabel('loss')\n",
    "    return ax\n",
    "\n",
    "plot_history(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6d15ee-4bd2-49e9-bd7e-bd525010fff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a0b4f0-a3d1-4575-a6b9-060dc6a3702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#code to export results into a file that can be used for triplet loss?\n",
    "import itertools\n",
    "def subgroup_neighbors(y,ypred,agg_func=np.nansum,stringify_index=False):\n",
    "    classes = [sorted(np.unique(yy)) for yy in y]\n",
    "    labels = Constants.labels[:]\n",
    "    class_combos = list(itertools.product(*classes))\n",
    "    ooc = {}\n",
    "    ic = {}\n",
    "    for combo in class_combos:\n",
    "        probs = [yp[:,c] for c,yp in zip(combo,ypred)]\n",
    "        total_prob = agg_func(probs,axis=0)\n",
    "        true_class = np.all(np.stack([yy == c for yy,c in zip(y,combo)]),axis=0)\n",
    "        ooc_probs = total_prob*(~true_class).astype(int)\n",
    "        ic_probs = total_prob*true_class.astype(int)\n",
    "        if stringify_index:\n",
    "            key ='-'.join([str(c) for c in combo])\n",
    "        else:\n",
    "            key = combo\n",
    "        ooc[key] = ooc_probs\n",
    "        ic[key] = ic_probs\n",
    "    return ooc,ic\n",
    "\n",
    "def add_triplet_values(model,label_df,y=None,ypred=None,use_histogram=False,**kwargs):\n",
    "    if y is None or ypred is None:\n",
    "        y,ypred = eval_labels(model,label_df,use_histogram=use_histogram,filter_nonfaces=False)\n",
    "    ooc, ic = subgroup_neighbors(y,ypred,stringify_index=True,**kwargs)\n",
    "    newdf = []\n",
    "    pos = 0\n",
    "    for i,row in label_df.copy().iterrows():\n",
    "        entry = row.to_dict()\n",
    "        for k,v in ooc.items():\n",
    "            anchor = ic.get(k)\n",
    "            entry[k + '_anchor'] = anchor[pos]\n",
    "            entry[k + '_bias'] = v[pos]\n",
    "        pos += 1\n",
    "        newdf.append(entry)\n",
    "    return pd.DataFrame(newdf)\n",
    "   \n",
    "HISTOGRAM = False\n",
    "SURNAME = 'balanceddual'\n",
    "print('train_data_augmented_' + SURNAME + '.csv')\n",
    "print('validation_data_augmented_' + SURNAME + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc24e11-b596-4989-ac72-5626fb0f50be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y, train_ypred = eval_labels(model,train_labels,use_histogram=HISTOGRAM,filter_nonfaces=False)\n",
    "temp = add_triplet_values(model,train_labels,y=train_y,ypred=train_ypred, use_histogram=HISTOGRAM)\n",
    "temp.to_csv('train_data_augmented_' + SURNAME + '.csv')\n",
    "print(temp.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac97a0c-c901-4c80-800c-82363ea652cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_y, val_ypred = eval_labels(model,val_labels,use_histogram=HISTOGRAM,filter_nonfaces=False)\n",
    "temp_v = add_triplet_values(model,val_labels,y=val_y,ypred=val_ypred,use_histogram=HISTOGRAM)\n",
    "temp_v.to_csv('validation_data_augmented_' + SURNAME + '.csv')\n",
    "temp_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10981154-0f16-4f61-bdeb-2269ff63ad9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b90e0dd-1797-4104-ba78-760c798f6d17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
