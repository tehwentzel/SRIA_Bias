{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5242e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d450bdf-5923-4b87-8b61-6133cd4d7491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.ndimage import rotate\n",
    "import Utils\n",
    "from Utils import Constants\n",
    "import cv2\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "from Models import *\n",
    "from DataLoaders import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb156980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>skin_tone</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>is_face</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN0001.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN0002.png</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN0005.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN0007.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN0009.png</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6837</th>\n",
       "      <td>TRAIN9992.png</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6838</th>\n",
       "      <td>TRAIN9993.png</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6839</th>\n",
       "      <td>TRAIN9995.png</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6840</th>\n",
       "      <td>TRAIN9998.png</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6841</th>\n",
       "      <td>TRAIN9999.png</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6842 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               name  skin_tone  gender  age  is_face\n",
       "0     TRAIN0001.png          0       0    1    False\n",
       "1     TRAIN0002.png          5       1    0     True\n",
       "2     TRAIN0005.png          1       1    0    False\n",
       "3     TRAIN0007.png          1       0    1     True\n",
       "4     TRAIN0009.png          7       0    1    False\n",
       "...             ...        ...     ...  ...      ...\n",
       "6837  TRAIN9992.png          4       0    2     True\n",
       "6838  TRAIN9993.png          1       1    1     True\n",
       "6839  TRAIN9995.png          8       0    1     True\n",
       "6840  TRAIN9998.png          4       1    1    False\n",
       "6841  TRAIN9999.png          3       1    1     True\n",
       "\n",
       "[6842 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = pd.read_csv('train_data_clean.csv')\n",
    "test_labels = pd.read_csv('test_data_clean.csv')\n",
    "validation_labels = pd.read_csv('validation_data_clean.csv')\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5bca33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4869, 5)\n",
      "(1209, 5)\n",
      "model being saved to ../../data/models/dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2\n",
      "epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 6.265864177626007 train accuracy [0.17110026148813112, 0.4962200437273298, 0.5995149217089828]\n",
      "val loss 6.054253431466909 val accuracy [0.20324785778155693, 0.5112820451076214, 0.5788034108968881] val f1 [0.15425822654595742, 0.33729202242997974, 0.36569592585930455]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 1\n",
      "train loss 6.042875338573845 train accuracy [0.19851818422273715, 0.4966282066033811, 0.6299526618451489]\n",
      "val loss 5.982596544119028 val accuracy [0.19102563537084138, 0.5112820451076214, 0.7028204936247605] val f1 [0.10486833120767887, 0.33729202242997974, 0.33180152682157665]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 2\n",
      "train loss 6.010139163659543 train accuracy [0.1972227088954984, 0.4966282066033811, 0.6537888062243559]\n",
      "val loss 5.8998511387751655 val accuracy [0.20324785778155693, 0.5112820451076214, 0.7913675078978906] val f1 [0.1682448874299343, 0.33729202242997974, 0.3875153133502373]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 3\n",
      "train loss 5.9724811145237515 train accuracy [0.19491570093193833, 0.5078526954261624, 0.7115232007844108]\n",
      "val loss 5.838854643014761 val accuracy [0.1977777716058951, 0.586666655081969, 0.872307681120359] val f1 [0.09451836347579956, 0.22962686190238366, 0.4333345408623035]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 4\n",
      "train loss 5.933743652032346 train accuracy [0.1966104647334741, 0.5496983029404465, 0.7314729216147442]\n",
      "val loss 5.82396910740779 val accuracy [0.21008546478473222, 0.6190598194415753, 0.7728205002271212] val f1 [0.10802789720205161, 0.2548022602613156, 0.372847155882762]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 5\n",
      "train loss 5.886036425220723 train accuracy [0.20677313923227544, 0.5779946616717747, 0.7407985633733322]\n",
      "val loss 5.75367964231051 val accuracy [0.2232478570479613, 0.6483760567811819, 0.8546153627909147] val f1 [0.11638079984829976, 0.31023696752694935, 0.4260658553013435]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 6\n",
      "train loss 5.889377788621552 train accuracy [0.20831410313139156, 0.5658207511415287, 0.7288287269825838]\n",
      "val loss 5.794732130490816 val accuracy [0.21623930965478605, 0.6152136600934542, 0.819059812105619] val f1 [0.09609442949295044, 0.25173131089944106, 0.40063035717377293]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 7\n",
      "train loss 5.85659392999143 train accuracy [0.22137532702514104, 0.5897190029523811, 0.7530641677428265]\n",
      "val loss 5.719619971055251 val accuracy [0.2332478566811635, 0.6436752035067632, 0.8823076715836158] val f1 [0.12076352250117522, 0.3018677097100478, 0.4388180168775412]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 8\n",
      "train loss 5.850789868101781 train accuracy [0.2195592945327564, 0.5856787811736671, 0.752839377948216]\n",
      "val loss 5.737872013678918 val accuracy [0.22863247188237998, 0.6430769150073712, 0.8676068186759949] val f1 [0.11223614788972415, 0.2921022910338182, 0.43087342839974624]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 9\n",
      "train loss 5.831268154844945 train accuracy [0.23030463742966556, 0.5962496156595192, 0.7575125475319064]\n",
      "val loss 5.673471927642822 val accuracy [0.2740170886883369, 0.665299131320073, 0.877692277614887] val f1 [0.13939165495909178, 0.3253276852461008, 0.43762528667083156]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 10\n",
      "train loss 5.827571246088768 train accuracy [0.24085477085746065, 0.5929843132593193, 0.7594616802371278]\n",
      "val loss 5.746968636145959 val accuracy [0.2370940114443119, 0.6259828897622916, 0.8398290368226858] val f1 [0.10939018371013495, 0.27301058975549847, 0.41341049854572004]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 11\n",
      "train loss 5.805424223140794 train accuracy [0.24675243363088492, 0.5954332923402592, 0.7598195647706791]\n",
      "val loss 5.699527153602014 val accuracy [0.2600854675357158, 0.6398290487436148, 0.8329914349776047] val f1 [0.14082512288139418, 0.304706497834279, 0.4152984435741718]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 12\n",
      "train loss 5.787361544005725 train accuracy [0.2549364019413384, 0.6014226413502985, 0.7682578952945008]\n",
      "val loss 5.653175097245437 val accuracy [0.25863247422071606, 0.6668375913913434, 0.85529913352086] val f1 [0.12910283070344192, 0.316765322135045, 0.4262648591628441]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 13\n",
      "train loss 5.788686937215377 train accuracy [0.2561608930023349, 0.5966370823431988, 0.763064160638926]\n",
      "val loss 5.6349729758042555 val accuracy [0.2755555487596072, 0.6614529811418973, 0.876837588273562] val f1 [0.14218202577187464, 0.31056575591747576, 0.4368519691320566]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 14\n",
      "train loss 5.751688480377197 train accuracy [0.263395437172481, 0.6061875078142905, 0.7658798998715927]\n",
      "val loss 5.611273765563965 val accuracy [0.2778632388665126, 0.6660683613557082, 0.8846153754454392] val f1 [0.14404398661393386, 0.31785637828019947, 0.43963884161068845]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 15\n",
      "train loss 5.757067193790358 train accuracy [0.27096716177706814, 0.6021265770707812, 0.7703696988066848]\n",
      "val loss 5.621171694535476 val accuracy [0.27709400997712064, 0.673760670882005, 0.8706837525734534] val f1 [0.14055219808450112, 0.31063382212932295, 0.4319346111554366]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 16\n",
      "train loss 5.746765827646061 train accuracy [0.26601892131931926, 0.6078408652422379, 0.7718603756962991]\n",
      "val loss 5.6005976016704855 val accuracy [0.29709401153601134, 0.6799999933976394, 0.8814529684873728] val f1 [0.1524903321495423, 0.32863263900463396, 0.4390852130376376]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 17\n",
      "train loss 5.722106729234968 train accuracy [0.274161483864395, 0.6070245376655033, 0.7739100675193631]\n",
      "val loss 5.60945173410269 val accuracy [0.2770085386358775, 0.6675213529513433, 0.8823076715836158] val f1 [0.14198966467609772, 0.3115543585557204, 0.4396240825836475]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 18\n",
      "train loss 5.738397938864572 train accuracy [0.2729162902248149, 0.6021679864854229, 0.7671664989724452]\n",
      "val loss 5.582256977374737 val accuracy [0.30786324120484865, 0.6768376001944909, 0.8891452734286969] val f1 [0.16270832086984927, 0.3224033690415896, 0.44277283549308777]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 19\n",
      "train loss 5.709383273611263 train accuracy [0.2906506888720454, 0.6148713231086731, 0.7741762606465087]\n",
      "val loss 5.598809829125037 val accuracy [0.2962393124516194, 0.6745299055026128, 0.8645298893635089] val f1 [0.1577238982113508, 0.3128406497148367, 0.4281412042104281]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 20\n",
      "train loss 5.694729766067193 train accuracy [0.28816029763951595, 0.6162082102833962, 0.7760129948051608]\n",
      "val loss 5.579051971435547 val accuracy [0.2954700766847684, 0.6823076789195721, 0.8729914289254409] val f1 [0.15486046413962656, 0.324611267218223, 0.4349204943730281]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 21\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 5.674396067249532 train accuracy [0.3000887261361492, 0.6244838639181487, 0.7838597857222265]\n",
      "val loss 5.597300896277795 val accuracy [0.29786324271788966, 0.6915384393471938, 0.7982905736336341] val f1 [0.1486168526686155, 0.33689115139154285, 0.39832684856194717]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 22\n",
      "train loss 5.6758275226670865 train accuracy [0.29314994842422254, 0.6245755541081331, 0.7838804904295473]\n",
      "val loss 5.5753099001370945 val accuracy [0.29931623488664627, 0.6799145157520587, 0.8783760437598596] val f1 [0.15752129170757073, 0.328329188319353, 0.43675888730929446]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 23\n",
      "train loss 5.665095679614009 train accuracy [0.2996302812683339, 0.6255752614566258, 0.7880331058891452]\n",
      "val loss 5.555079496823824 val accuracy [0.3055555488054569, 0.6815384442989643, 0.8814529730723455] val f1 [0.15674770738069826, 0.327453239605977, 0.4388441787316249]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 24\n",
      "train loss 5.663533609740588 train accuracy [0.30096715992810774, 0.6278615691223923, 0.7900325157204453]\n",
      "val loss 5.553327340346116 val accuracy [0.3093162356660916, 0.6837606705152072, 0.8745298981666565] val f1 [0.1656527378811286, 0.3313877055278191, 0.4356939265361199]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 25\n",
      "train loss 5.661334135094467 train accuracy [0.2984471965809258, 0.6309227882599344, 0.7879207146411039]\n",
      "val loss 5.574904661912185 val accuracy [0.31170939482175386, 0.6752136578926673, 0.8567521205315223] val f1 [0.1663900321492782, 0.320766412294828, 0.42683005103698146]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 26\n",
      "train loss 5.648625597661855 train accuracy [0.3102218192450854, 0.6288908470650109, 0.7878290244511196]\n",
      "val loss 5.603582015404334 val accuracy [0.27854699985339093, 0.6753846085988559, 0.8745299027516291] val f1 [0.1402234910772397, 0.32689854617302233, 0.4358359850369967]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 27\n",
      "train loss 5.648629538866938 train accuracy [0.3147323210628665, 0.6196775953380429, 0.786012990134103]\n",
      "val loss 5.559192620790922 val accuracy [0.3093162322273621, 0.6830769043702346, 0.8776068228941697] val f1 [0.16637773267351663, 0.32777706820231217, 0.4356171442912175]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 28\n",
      "train loss 5.649873704326396 train accuracy [0.3147116169637563, 0.6246672430816962, 0.7838597857222265]\n",
      "val loss 5.55155611038208 val accuracy [0.30863247353297013, 0.6907692230664767, 0.8745298981666565] val f1 [0.1524088354064868, 0.330029152906858, 0.4338992123420422]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 29\n",
      "train loss 5.617233957563128 train accuracy [0.3174060868973635, 0.637207915588301, 0.7969505847716818]\n",
      "val loss 5.552899910853459 val accuracy [0.2977777702304033, 0.6860683606221125, 0.8683760578815753] val f1 [0.1595945068849967, 0.32603461238054127, 0.43090574787213254]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 30\n",
      "train loss 5.625536587773537 train accuracy [0.32060927943307527, 0.626350179010508, 0.792593886657637]\n",
      "val loss 5.590494742760291 val accuracy [0.30478631533109224, 0.6599145210706271, 0.8791452783804673] val f1 [0.16072780409684548, 0.31898298171850353, 0.4377763248406924]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 31\n",
      "train loss 5.626893218682737 train accuracy [0.3180686128990991, 0.6272493150769448, 0.7943803424737892]\n",
      "val loss 5.5514020553001995 val accuracy [0.31709401538738835, 0.6822222150289096, 0.8729914380953863] val f1 [0.163505413211309, 0.321572108910634, 0.4340872512413905]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 32\n",
      "train loss 5.604556871920216 train accuracy [0.33507837203084206, 0.632135449623575, 0.7910529229105735]\n",
      "val loss 5.552559669201191 val accuracy [0.3177777694968077, 0.6838461344058697, 0.8668375978103051] val f1 [0.17170938878105238, 0.33068613364146304, 0.43175432773736805]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 33\n",
      "train loss 5.632466773597562 train accuracy [0.31791481193231075, 0.6319224956084271, 0.7920733337499657]\n",
      "val loss 5.523227288172795 val accuracy [0.33410255496318525, 0.67521366247764, 0.8869230609673721] val f1 [0.18010791677695054, 0.32065688417508054, 0.44128265518408555]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 34\n",
      "train loss 5.6027138379155375 train accuracy [0.3352410428378047, 0.6300857602333536, 0.7878793027936196]\n",
      "val loss 5.514388781327468 val accuracy [0.3324786275625229, 0.6752136578926673, 0.8830769062042236] val f1 [0.17413217746294463, 0.3289610216250786, 0.4392242615039532]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 35\n",
      "train loss 5.602270048491809 train accuracy [0.32106772430089053, 0.6397692828762288, 0.7984619724507235]\n",
      "val loss 5.539996770712046 val accuracy [0.3132478560392673, 0.6876922983389634, 0.8676922917366028] val f1 [0.15791837412577409, 0.3357920612280185, 0.43241907312319827]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 36\n",
      "train loss 5.597130824108513 train accuracy [0.3299970347054151, 0.6323099549935789, 0.796829319730097]\n",
      "val loss 5.55484492962177 val accuracy [0.30709401346169984, 0.6822222058589642, 0.8791452875504127] val f1 [0.16877693281723902, 0.33166380111987775, 0.4370957612991333]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 37\n",
      "train loss 5.5953927526668625 train accuracy [0.3281603005467629, 0.6374326962597516, 0.7959922917035162]\n",
      "val loss 5.496029523702768 val accuracy [0.3371794796906985, 0.6938461386240445, 0.8892307510742774] val f1 [0.1765102377304664, 0.332454468195255, 0.44285463369809663]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 38\n",
      "train loss 5.577150442162338 train accuracy [0.34101744330659206, 0.6419017910957336, 0.791981638694296]\n",
      "val loss 5.515389112325815 val accuracy [0.3426495652932387, 0.6861538382676932, 0.8822222031079806] val f1 [0.18455085846093985, 0.3288785242117368, 0.43879836797714233]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 39\n",
      "train loss 5.571464606693813 train accuracy [0.34700679657410605, 0.6385033921319612, 0.7906654683911071]\n",
      "val loss 5.554637798896203 val accuracy [0.3030769160160652, 0.6868375998276931, 0.8822222031079806] val f1 [0.16697328480390403, 0.32695783560092634, 0.4385326092059796]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 40\n",
      "train loss 5.571291398028938 train accuracy [0.3431292425613014, 0.6462082060015931, 0.7986660575380131]\n",
      "val loss 5.5822547399080715 val accuracy [0.29940170164291674, 0.6845299005508423, 0.8536751958040091] val f1 [0.15113269537687302, 0.32248806724181545, 0.4216459553975325]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 41\n",
      "train loss 5.569425446646554 train accuracy [0.3474859418917675, 0.6395445003801462, 0.791523198692166]\n",
      "val loss 5.5168555699861965 val accuracy [0.34179486907445467, 0.6983760503622202, 0.8668375886403598] val f1 [0.18324882823687333, 0.33350072227991545, 0.4299549850133749]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train loss 5.53846381635082 train accuracy [0.3558739958977213, 0.6447589312280927, 0.8005944770209643]\n",
      "val loss 5.542310641362117 val accuracy [0.3325640971844013, 0.6760683564039377, 0.8452136516571045] val f1 [0.17393367680219504, 0.32748963282658505, 0.4206194304502927]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 43\n",
      "train loss 5.554860309678681 train accuracy [0.35073054566675305, 0.645871031041048, 0.8016444639283784]\n",
      "val loss 5.530455625974215 val accuracy [0.3279487078006451, 0.6776068210601807, 0.8745298981666565] val f1 [0.17288227952443636, 0.32813676045491147, 0.43512069949736965]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 44\n",
      "train loss 5.518769380997639 train accuracy [0.3675983335290636, 0.6502484302131497, 0.7999615292159878]\n",
      "val loss 5.519388785729041 val accuracy [0.3317093929419151, 0.6899999930308416, 0.880683747621683] val f1 [0.17815325581110442, 0.33358871707549465, 0.43813355610920834]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 45\n",
      "train loss 5.527920985708431 train accuracy [0.3655575185405965, 0.6501153354742089, 0.789982236161524]\n",
      "val loss 5.581608588878925 val accuracy [0.29153845745783585, 0.6814529804083017, 0.8690598102716299] val f1 [0.15416095061944082, 0.33195123764184803, 0.43218090213262117]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 46\n",
      "train loss 5.552616080459283 train accuracy [0.3504051967542999, 0.6424223464362475, 0.7949008953814604]\n",
      "val loss 5.592570084791917 val accuracy [0.2938461464184981, 0.6791452903013963, 0.8715384419147785] val f1 [0.15920977638317987, 0.33502692213425267, 0.43426276170290434]\n",
      "saved history to ../../data/results/history_dual_dualfacenet_h1000_st600_a400_g400_ed4_std2_ad2_gd2.csv\n",
      "epoch 47\n",
      "curr loss 5.4906511306762695 step 1  | \r"
     ]
    }
   ],
   "source": [
    "def save_train_history(model,history,root=''):\n",
    "    model_name = model.get_identifier()\n",
    "    \n",
    "    df = pd.DataFrame(history)\n",
    "    df['model'] = model_name\n",
    "    string = root + 'results/history_' + model_name + '.csv'\n",
    "    df.to_csv(string,index=False)\n",
    "    print('saved history to',string)\n",
    "    return df, string\n",
    "\n",
    "def train_model(model,\n",
    "                train_df,\n",
    "                validation_df,\n",
    "                root,\n",
    "                epochs=300,\n",
    "                lr=.001,\n",
    "                batch_size=200,\n",
    "                patience = 20,\n",
    "                loss_weights = [2,1,.5],\n",
    "                save_path=None,\n",
    "                histogram =False,\n",
    "                upsample=False,\n",
    "                random_upsample=True,\n",
    "                softmax_upsample_weights=False,\n",
    "                upsample_validation=False,\n",
    "                random_upsample_validation=False,\n",
    "                **kwargs,\n",
    "               ):\n",
    "    if save_path is None:\n",
    "        save_path = root + 'models/'+ model.get_identifier()\n",
    "        if upsample:\n",
    "            save_path += '_balanced'\n",
    "    if upsample:\n",
    "        patience = int(patience/5) + 1\n",
    "    train_loader = FaceGenerator(train_df,Constants.data_root,\n",
    "                                 batch_size=batch_size,\n",
    "                                 upsample=upsample,\n",
    "                                 random_upsample=random_upsample,\n",
    "                                 softmax=softmax_upsample_weights,\n",
    "                                 **kwargs)\n",
    "    validation_loader = FaceGenerator(validation_df,Constants.data_root,\n",
    "                                      validation=True,\n",
    "                                      batch_size=batch_size,\n",
    "                                      upsample=upsample_validation,\n",
    "                                     random_upsample=random_upsample_validation,\n",
    "                                     softmax=softmax_upsample_weights,\n",
    "                                      **kwargs)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    format_y = lambda y: y.long().to(device)\n",
    "    \n",
    "    def get_loss(m,xin,ytrue):\n",
    "        outputs = m(xin)\n",
    "        losses = [loss_fn(ypred.float(),format_y(y)) for y,ypred in zip(ytrue,outputs)]\n",
    "        l1 = torch.mul(loss_weights[0],losses[0])\n",
    "        l2 =  torch.mul(loss_weights[1],losses[1])\n",
    "        l3 =  torch.mul(loss_weights[2],losses[2])\n",
    "        total_losses = l1 + l2 + l3\n",
    "        return outputs,total_losses\n",
    "\n",
    "    \n",
    "    def train_epoch():\n",
    "        running_loss = 0\n",
    "        running_accuracy = [0,0,0]\n",
    "        curr_loss = 0\n",
    "        count = 0\n",
    "        for i, [x_batch, y_batch] in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            if histogram:\n",
    "                xh = torch_color_histogram(torch.clone(x_batch))\n",
    "                xh = xh.to(device)\n",
    "                xxb = x_batch.to(device)\n",
    "                xh.requires_grad_(True)\n",
    "                xxb.requires_grad_(True)\n",
    "                xb = [xxb,xh]\n",
    "            else:\n",
    "                xb = x_batch.to(device)\n",
    "                xb.requires_grad_(True)\n",
    "            outputs,total_losses = get_loss(model, xb,y_batch)\n",
    "            total_losses.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += total_losses.item()\n",
    "            print('curr loss',total_losses.item(), 'step',i,' | ',end='\\r')\n",
    "            count += 1\n",
    "            with torch.no_grad():\n",
    "                for i,(y,ypred) in enumerate(zip(y_batch,outputs)):\n",
    "                    accuracy = Utils.categorical_accuracy(ypred.float(),format_y(y))\n",
    "                    running_accuracy[i] += accuracy.item()\n",
    "        return running_loss/count, [a/count for a in running_accuracy]\n",
    "    \n",
    "    def val_epoch():\n",
    "        running_loss = 0\n",
    "        running_accuracy = [0,0,0]\n",
    "        running_f1 = [0,0,0]\n",
    "        count = 0\n",
    "        for i, [x_batch, y_batch] in enumerate(validation_loader):\n",
    "            if histogram:\n",
    "                xb = add_batch_histogram(x_batch,device=device,grad=False)\n",
    "            else:\n",
    "                xb = x_batch.to(device)\n",
    "            outputs = model(xb)\n",
    "            outputs,total_losses = get_loss(model,xb,y_batch)\n",
    "            running_loss += total_losses.item()\n",
    "            count += 1\n",
    "            for i,(y,ypred) in enumerate(zip(y_batch, outputs)):\n",
    "                accuracy = Utils.categorical_accuracy(ypred.float(),format_y(y))\n",
    "                f1, precision, recall = Utils.macro_f1(torch.argmax(ypred.float(),axis=1),format_y(y))\n",
    "                running_f1[i] += f1.item()\n",
    "                running_accuracy[i] += accuracy.item()\n",
    "        return running_loss/count, [a/count for a in running_accuracy], [f/count for f in running_f1]\n",
    "    \n",
    "    \n",
    "    best_val_loss = 100000\n",
    "    steps_since_improvement = 0\n",
    "    hist = []\n",
    "    best_weights = model.state_dict()\n",
    "    print('model being saved to',save_path)\n",
    "    for epoch in range(epochs):\n",
    "        print('epoch',epoch)\n",
    "        model.train(True)\n",
    "        avg_loss, avg_acc = train_epoch()\n",
    "        print('train loss', avg_loss, 'train accuracy', avg_acc)\n",
    "        model.eval()\n",
    "        val_loss, val_acc, val_f1 = val_epoch()\n",
    "        print('val loss', val_loss, 'val accuracy', val_acc, 'val f1',val_f1)\n",
    "#         torch.save(model.state_dict(), save_path + '_epoch' + str(epoch))\n",
    "        if best_val_loss > val_loss:\n",
    "            best_weights = model.state_dict()\n",
    "            best_val_loss = val_loss\n",
    "            steps_since_improvement = 0\n",
    "            if epoch > 1:\n",
    "                torch.save(model,save_path)\n",
    "                torch.save(model.state_dict(),save_path+'_states')\n",
    "        else:\n",
    "            steps_since_improvement += 1\n",
    "        \n",
    "        hist_entry = {\n",
    "            'epoch': epoch,\n",
    "            'train_loss': avg_loss,\n",
    "            'train_acc':avg_acc,\n",
    "            'val_loss':val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'lr': lr,\n",
    "            'loss_weights': '_'.join([str(l) for l in loss_weights])\n",
    "        }\n",
    "        hist.append(hist_entry)\n",
    "        save_train_history(model,hist,root=root)\n",
    "        if steps_since_improvement > patience:\n",
    "            break\n",
    "    return model,hist\n",
    "\n",
    "m,h = train_model(\n",
    "    DualFacenetModel(\n",
    "        hidden_dims = [1000],\n",
    "        embedding_dropout=.4,\n",
    "        st_dropout = .2,\n",
    "        age_dropout = .2,\n",
    "        gender_dropout = .2,\n",
    "    ),\n",
    "    train_labels,\n",
    "    validation_labels,\n",
    "    Constants.data_root,\n",
    "    batch_size=100,\n",
    "#     histogram=True,\n",
    "    lr=.0001,\n",
    "#     lr=10,\n",
    "#     upsample=False,\n",
    ")\n",
    "del m\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0f5564",
   "metadata": {},
   "outputs": [],
   "source": [
    "DualHistogramModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30424a60-e49f-43d8-8b19-e711c7c82754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3470cf72-d79e-4449-8b77-340620ba6895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
