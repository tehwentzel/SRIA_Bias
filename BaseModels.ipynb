{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5242e5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d450bdf-5923-4b87-8b61-6133cd4d7491",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from scipy.ndimage import rotate\n",
    "import Utils\n",
    "from Utils import Constants\n",
    "import cv2\n",
    "from facenet_pytorch import InceptionResnetV1\n",
    "from Models import *\n",
    "from DataLoaders import *\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb156980",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels = pd.read_csv('train_data_clean.csv')\n",
    "# test_labels = pd.read_csv('test_data_clean.csv')\n",
    "# validation_labels = pd.read_csv('validation_data_clean.csv')\n",
    "# train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc8e146b-e043-444f-bdcc-fd3666297647",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4869, 167)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.3289, 0.3306, 0.3342,  ..., 0.5000, 0.4417, 0.4948],\n",
       "          [0.3314, 0.3346, 0.3351,  ..., 0.4817, 0.4601, 0.4430],\n",
       "          [0.3299, 0.3360, 0.3431,  ..., 0.5030, 0.5116, 0.4616],\n",
       "          ...,\n",
       "          [0.0216, 0.0146, 0.0130,  ..., 0.0130, 0.0091, 0.0061],\n",
       "          [0.0249, 0.0159, 0.0117,  ..., 0.0118, 0.0089, 0.0048],\n",
       "          [0.0290, 0.0180, 0.0117,  ..., 0.0136, 0.0107, 0.0066]],\n",
       "\n",
       "         [[0.3826, 0.3831, 0.3857,  ..., 0.3584, 0.2937, 0.3442],\n",
       "          [0.3905, 0.3875, 0.3875,  ..., 0.3459, 0.3147, 0.2993],\n",
       "          [0.3845, 0.3886, 0.3956,  ..., 0.3805, 0.3664, 0.3142],\n",
       "          ...,\n",
       "          [0.0911, 0.0829, 0.0850,  ..., 0.0849, 0.0808, 0.0776],\n",
       "          [0.0943, 0.0854, 0.0835,  ..., 0.0836, 0.0808, 0.0767],\n",
       "          [0.0947, 0.0838, 0.0812,  ..., 0.0854, 0.0826, 0.0785]],\n",
       "\n",
       "         [[0.3841, 0.3853, 0.3889,  ..., 0.2742, 0.2167, 0.2722],\n",
       "          [0.3885, 0.3895, 0.3898,  ..., 0.2643, 0.2403, 0.2273],\n",
       "          [0.3858, 0.3908, 0.3972,  ..., 0.3107, 0.2877, 0.2324],\n",
       "          ...,\n",
       "          [0.1043, 0.0944, 0.0971,  ..., 0.1015, 0.0975, 0.0946],\n",
       "          [0.1110, 0.0999, 0.0939,  ..., 0.1002, 0.0974, 0.0933],\n",
       "          [0.1133, 0.1022, 0.0948,  ..., 0.1020, 0.0992, 0.0951]]],\n",
       "\n",
       "\n",
       "        [[[0.1306, 0.1091, 0.1049,  ..., 0.3065, 0.2269, 0.1828],\n",
       "          [0.0414, 0.0626, 0.0699,  ..., 0.3631, 0.3037, 0.2589],\n",
       "          [0.0054, 0.0675, 0.0656,  ..., 0.4083, 0.3564, 0.2676],\n",
       "          ...,\n",
       "          [0.3821, 0.3969, 0.4161,  ..., 0.4977, 0.5022, 0.5720],\n",
       "          [0.3568, 0.3876, 0.3768,  ..., 0.5198, 0.5419, 0.5960],\n",
       "          [0.3379, 0.3540, 0.3319,  ..., 0.5712, 0.6309, 0.6748]],\n",
       "\n",
       "         [[0.0969, 0.0876, 0.1005,  ..., 0.1900, 0.1323, 0.1273],\n",
       "          [0.0971, 0.1226, 0.1129,  ..., 0.1858, 0.2089, 0.1782],\n",
       "          [0.0965, 0.1079, 0.0949,  ..., 0.2188, 0.2272, 0.1885],\n",
       "          ...,\n",
       "          [0.3473, 0.3780, 0.3714,  ..., 0.4829, 0.4876, 0.5195],\n",
       "          [0.3689, 0.3799, 0.3598,  ..., 0.4723, 0.4891, 0.4862],\n",
       "          [0.2958, 0.2926, 0.2463,  ..., 0.4569, 0.4798, 0.5184]],\n",
       "\n",
       "         [[0.0752, 0.1902, 0.1890,  ..., 0.1528, 0.1010, 0.0079],\n",
       "          [0.0419, 0.1092, 0.1214,  ..., 0.0955, 0.0967, 0.0669],\n",
       "          [0.0424, 0.1049, 0.1087,  ..., 0.1259, 0.1350, 0.0944],\n",
       "          ...,\n",
       "          [0.3375, 0.3405, 0.3183,  ..., 0.4565, 0.4407, 0.4567],\n",
       "          [0.2731, 0.3177, 0.3039,  ..., 0.4490, 0.4538, 0.4639],\n",
       "          [0.2363, 0.2298, 0.2480,  ..., 0.4154, 0.4258, 0.3959]]],\n",
       "\n",
       "\n",
       "        [[[0.4802, 0.4827, 0.4828,  ..., 0.6080, 0.5936, 0.5737],\n",
       "          [0.4940, 0.4917, 0.4923,  ..., 0.6051, 0.5937, 0.5755],\n",
       "          [0.5001, 0.4950, 0.4887,  ..., 0.6010, 0.5972, 0.5873],\n",
       "          ...,\n",
       "          [0.2707, 0.2758, 0.2855,  ..., 0.3143, 0.3337, 0.3514],\n",
       "          [0.2694, 0.2760, 0.2749,  ..., 0.2982, 0.3102, 0.3348],\n",
       "          [0.2654, 0.2670, 0.2672,  ..., 0.2913, 0.3043, 0.3201]],\n",
       "\n",
       "         [[0.5661, 0.5675, 0.5682,  ..., 0.6588, 0.6518, 0.6399],\n",
       "          [0.5700, 0.5683, 0.5699,  ..., 0.6590, 0.6499, 0.6410],\n",
       "          [0.5693, 0.5653, 0.5650,  ..., 0.6570, 0.6540, 0.6437],\n",
       "          ...,\n",
       "          [0.2892, 0.2917, 0.3038,  ..., 0.3242, 0.3469, 0.3660],\n",
       "          [0.2845, 0.2906, 0.2968,  ..., 0.3044, 0.3212, 0.3488],\n",
       "          [0.2665, 0.2747, 0.2820,  ..., 0.2970, 0.3143, 0.3297]],\n",
       "\n",
       "         [[0.3959, 0.3946, 0.3937,  ..., 0.4475, 0.4318, 0.4146],\n",
       "          [0.4027, 0.4014, 0.3980,  ..., 0.4458, 0.4338, 0.4170],\n",
       "          [0.4031, 0.3992, 0.3940,  ..., 0.4368, 0.4316, 0.4198],\n",
       "          ...,\n",
       "          [0.3127, 0.3182, 0.3301,  ..., 0.3386, 0.3680, 0.3919],\n",
       "          [0.3010, 0.3147, 0.3203,  ..., 0.3124, 0.3346, 0.3666],\n",
       "          [0.2700, 0.2815, 0.2916,  ..., 0.3013, 0.3196, 0.3417]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0.4118, 0.4080, 0.3992,  ..., 0.2377, 0.2537, 0.2533],\n",
       "          [0.3853, 0.4029, 0.4142,  ..., 0.2045, 0.2075, 0.2282],\n",
       "          [0.4134, 0.4232, 0.4118,  ..., 0.1872, 0.1899, 0.2112],\n",
       "          ...,\n",
       "          [0.1204, 0.1170, 0.1079,  ..., 0.2238, 0.2319, 0.2667],\n",
       "          [0.0937, 0.1124, 0.1140,  ..., 0.2018, 0.2064, 0.2072],\n",
       "          [0.0551, 0.1063, 0.1295,  ..., 0.1840, 0.1824, 0.1411]],\n",
       "\n",
       "         [[0.3187, 0.3067, 0.3125,  ..., 0.1230, 0.1266, 0.1614],\n",
       "          [0.3316, 0.3291, 0.3238,  ..., 0.1342, 0.1224, 0.1304],\n",
       "          [0.3464, 0.3423, 0.3236,  ..., 0.1275, 0.1121, 0.1378],\n",
       "          ...,\n",
       "          [0.0352, 0.0806, 0.1164,  ..., 0.0745, 0.0941, 0.0968],\n",
       "          [0.0177, 0.0614, 0.0930,  ..., 0.0569, 0.0746, 0.0704],\n",
       "          [0.0092, 0.0350, 0.0582,  ..., 0.0358, 0.0513, 0.0580]],\n",
       "\n",
       "         [[0.3205, 0.3089, 0.3144,  ..., 0.1415, 0.1594, 0.1265],\n",
       "          [0.3556, 0.3387, 0.3254,  ..., 0.1422, 0.1568, 0.1221],\n",
       "          [0.3744, 0.3458, 0.3391,  ..., 0.1392, 0.1644, 0.1454],\n",
       "          ...,\n",
       "          [0.0656, 0.0659, 0.0874,  ..., 0.0786, 0.0765, 0.0727],\n",
       "          [0.0471, 0.0561, 0.0730,  ..., 0.0745, 0.0663, 0.0608],\n",
       "          [0.0331, 0.0432, 0.0355,  ..., 0.0240, 0.0196, 0.0390]]],\n",
       "\n",
       "\n",
       "        [[[0.6005, 0.6158, 0.6197,  ..., 0.7991, 0.8349, 0.8664],\n",
       "          [0.6150, 0.6312, 0.6150,  ..., 0.8436, 0.8229, 0.8513],\n",
       "          [0.6191, 0.6366, 0.6175,  ..., 0.7948, 0.8092, 0.8143],\n",
       "          ...,\n",
       "          [0.2914, 0.2391, 0.2283,  ..., 0.7070, 0.7009, 0.7056],\n",
       "          [0.2501, 0.2204, 0.2042,  ..., 0.7210, 0.7042, 0.7022],\n",
       "          [0.2270, 0.1994, 0.1988,  ..., 0.7576, 0.7659, 0.7797]],\n",
       "\n",
       "         [[0.6020, 0.6163, 0.6154,  ..., 0.8526, 0.8805, 0.9118],\n",
       "          [0.6172, 0.6316, 0.6123,  ..., 0.8962, 0.8677, 0.8940],\n",
       "          [0.6236, 0.6367, 0.6134,  ..., 0.8508, 0.8572, 0.8607],\n",
       "          ...,\n",
       "          [0.5461, 0.4957, 0.4600,  ..., 0.5478, 0.5383, 0.5476],\n",
       "          [0.5142, 0.4783, 0.4372,  ..., 0.5625, 0.5445, 0.5450],\n",
       "          [0.4980, 0.4666, 0.4366,  ..., 0.5562, 0.5342, 0.5231]],\n",
       "\n",
       "         [[0.5827, 0.5972, 0.5970,  ..., 0.8632, 0.8883, 0.9196],\n",
       "          [0.5951, 0.6127, 0.5938,  ..., 0.9080, 0.8780, 0.9013],\n",
       "          [0.5966, 0.6161, 0.5930,  ..., 0.8622, 0.8665, 0.8679],\n",
       "          ...,\n",
       "          [0.6758, 0.6277, 0.5883,  ..., 0.4771, 0.4658, 0.4711],\n",
       "          [0.6504, 0.6109, 0.5739,  ..., 0.4903, 0.4714, 0.4718],\n",
       "          [0.6431, 0.6125, 0.5773,  ..., 0.5204, 0.5208, 0.5279]]],\n",
       "\n",
       "\n",
       "        [[[0.7118, 0.7019, 0.6681,  ..., 0.1498, 0.1590, 0.1416],\n",
       "          [0.7465, 0.7461, 0.7167,  ..., 0.1614, 0.1900, 0.2011],\n",
       "          [0.8302, 0.8176, 0.8038,  ..., 0.1827, 0.1647, 0.1784],\n",
       "          ...,\n",
       "          [0.2960, 0.3037, 0.3056,  ..., 0.0968, 0.1016, 0.0985],\n",
       "          [0.2742, 0.2733, 0.2726,  ..., 0.0969, 0.0995, 0.0977],\n",
       "          [0.2437, 0.2500, 0.2603,  ..., 0.0990, 0.1007, 0.1002]],\n",
       "\n",
       "         [[0.6621, 0.6572, 0.6298,  ..., 0.1224, 0.1342, 0.1168],\n",
       "          [0.6705, 0.6744, 0.6476,  ..., 0.1334, 0.1617, 0.1729],\n",
       "          [0.7415, 0.7282, 0.7147,  ..., 0.1483, 0.1281, 0.1396],\n",
       "          ...,\n",
       "          [0.2308, 0.2409, 0.2451,  ..., 0.0982, 0.1030, 0.0993],\n",
       "          [0.2182, 0.2197, 0.2221,  ..., 0.0983, 0.1009, 0.0991],\n",
       "          [0.1962, 0.2033, 0.2164,  ..., 0.1004, 0.1021, 0.1016]],\n",
       "\n",
       "         [[0.6401, 0.6381, 0.6091,  ..., 0.1060, 0.1200, 0.1024],\n",
       "          [0.6421, 0.6471, 0.6205,  ..., 0.1124, 0.1439, 0.1549],\n",
       "          [0.7117, 0.6992, 0.6848,  ..., 0.1218, 0.1027, 0.1148],\n",
       "          ...,\n",
       "          [0.1999, 0.2099, 0.2162,  ..., 0.1009, 0.1058, 0.1026],\n",
       "          [0.1912, 0.1913, 0.1939,  ..., 0.1011, 0.1036, 0.1018],\n",
       "          [0.1747, 0.1792, 0.1889,  ..., 0.1032, 0.1048, 0.1043]]]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = TripletFaceGenerator(pd.read_csv('train_data_augmented_balanceddual.csv'),Constants.data_root,skintone_patch_anchor_prob=0,validation=False,smote_prob=.5)\n",
    "[x,y] = next(iter(loader))\n",
    "x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145d2101-30bf-4210-97f7-00063c7a39b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [imgs_to_np(xx) for xx in x]\n",
    "Utils.plot_selection([images[0][0],images[1][0],images[2][0],images[0][2],images[1][2],images[2][2],images[0][3],images[1][3],images[2][3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "554f3326-b36b-4451-8f7e-80411ae66abb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0-1-0\n",
       "1       5-0-1\n",
       "2       1-0-1\n",
       "3       1-1-0\n",
       "4       7-1-0\n",
       "        ...  \n",
       "1706    3-1-0\n",
       "1707    2-2-0\n",
       "1708    1-0-1\n",
       "1709    4-1-1\n",
       "1710    0-1-0\n",
       "Name: subgroup, Length: 8553, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = pd.read_csv('train_data_augmented_balanceddual.csv')\n",
    "validation_labels = pd.read_csv('validation_data_augmented_balanceddual.csv')\n",
    "labels = pd.concat([train_labels,validation_labels]).drop('Unnamed: 0',axis=1)\n",
    "labels['subgroup'] = labels.apply(lambda row: '-'.join([str(row[s]) for s in Constants.labels]),axis=1)\n",
    "labels.subgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9215bb2d-608f-4675-bf23-a38b5424320e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Distribution of skin tone by age and gender')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def skintone(level):\n",
    "    rgb = (0,0,0)\n",
    "    if level == 0:\n",
    "        rgb = (246, 237, 228)\n",
    "    elif level == 1:\n",
    "        rgb = (243, 231, 219)\n",
    "    elif level == 2:\n",
    "        rgb = (247, 234, 208)\n",
    "    elif level == 3:\n",
    "        rgb = (234, 218, 186)\n",
    "    elif level == 4:\n",
    "        rgb = (215, 189, 150)\n",
    "    elif level == 5:\n",
    "        rgb = (160, 126, 86)\n",
    "    elif level == 6:\n",
    "        rgb = (130, 92,67)\n",
    "    elif level == 7:\n",
    "        rgb = (96, 65, 52)\n",
    "    elif level == 8:\n",
    "        rgb = (58,49,42)\n",
    "    else:\n",
    "        rgb = (41,36,32)\n",
    "    return (rgb[0]/255, rgb[1]/255, rgb[2]/255)\n",
    "\n",
    "xtemp = []\n",
    "ytemp = []\n",
    "colors = []\n",
    "ages = {\n",
    "    '0': '<18',\n",
    "    '1': '18-30',\n",
    "    '2': '31-60',\n",
    "    '3': '60+',\n",
    "}\n",
    "genders = {\n",
    "    '0': 'Women',\n",
    "    '1': 'Men',\n",
    "}\n",
    "for subgroup,subdf in labels.groupby('subgroup'):\n",
    "    xtemp.append(subdf.shape[0])\n",
    "    name = genders.get(subgroup[-1],'') + ' ' + ages.get(subgroup[2],'')\n",
    "    ytemp.append(name)\n",
    "    colors.append(skintone( int(subgroup[0]) ))\n",
    "fig, ax = plt.subplots(1,1,figsize=(20,10))\n",
    "ax.bar(ytemp,xtemp,color=colors)\n",
    "ax.set_title('Distribution of skin tone by age and gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5bca33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_train_history(model,history,root=''):\n",
    "    model_name = model.get_identifier()\n",
    "    \n",
    "    df = pd.DataFrame(history)\n",
    "    df['model'] = model_name\n",
    "    string = root + 'results/history_' + model_name + '.csv'\n",
    "    df.to_csv(string,index=False)\n",
    "    print('saved history to',string)\n",
    "    return df, string\n",
    "\n",
    "def train_model(model,\n",
    "                train_df,\n",
    "                validation_df,\n",
    "                root,\n",
    "                epochs=300,\n",
    "                lr=.0001,\n",
    "                batch_size=200,\n",
    "                patience = 20,\n",
    "                loss_weights = [5,2,1],\n",
    "                save_path=None,\n",
    "                histogram =False,\n",
    "                upsample=False,\n",
    "                random_upsample=True,\n",
    "                softmax_upsample_weights=False,\n",
    "                upsample_validation=False,\n",
    "                random_upsample_validation=False,\n",
    "                **kwargs,\n",
    "               ):\n",
    "    if save_path is None:\n",
    "        save_path = root + 'models/'+ model.get_identifier()\n",
    "        if random_upsample:\n",
    "            \n",
    "            save_path += '_rbalanced'\n",
    "            if softmax_upsample_weights:\n",
    "                save_path += 'soft'\n",
    "        elif upsample:\n",
    "            save_path += '_balanced'\n",
    "    if upsample:\n",
    "        patience = int(patience/5) + 1\n",
    "    train_loader = FaceGenerator(train_df,Constants.data_root,\n",
    "                                 batch_size=batch_size,\n",
    "                                 upsample=upsample,\n",
    "                                 random_upsample=random_upsample,\n",
    "                                 softmax=softmax_upsample_weights,\n",
    "                                 **kwargs)\n",
    "    validation_loader = FaceGenerator(validation_df,Constants.data_root,\n",
    "                                      validation=True,\n",
    "                                      batch_size=batch_size,\n",
    "                                      upsample=upsample_validation,\n",
    "                                     random_upsample=random_upsample_validation,\n",
    "                                     softmax=softmax_upsample_weights,\n",
    "                                      **kwargs)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    model.train()\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    format_y = lambda y: y.long().to(device)\n",
    "    \n",
    "    def get_loss(m,xin,ytrue):\n",
    "        outputs = m(xin)\n",
    "        losses = [loss_fn(ypred.float(),format_y(y)) for y,ypred in zip(ytrue,outputs)]\n",
    "        l1 = torch.mul(loss_weights[0],losses[0])\n",
    "        l2 =  torch.mul(loss_weights[1],losses[1])\n",
    "        l3 =  torch.mul(loss_weights[2],losses[2])\n",
    "        total_losses = l1 + l2 + l3\n",
    "        return outputs,total_losses\n",
    "\n",
    "    \n",
    "    def train_epoch():\n",
    "        running_loss = 0\n",
    "        running_accuracy = [0,0,0]\n",
    "        curr_loss = 0\n",
    "        count = 0\n",
    "        for i, [x_batch, y_batch] in enumerate(train_loader):\n",
    "            optimizer.zero_grad()\n",
    "            if histogram:\n",
    "                xh = torch_color_histogram(torch.clone(x_batch))\n",
    "                xh = xh.to(device)\n",
    "                xxb = x_batch.to(device)\n",
    "                xh.requires_grad_(True)\n",
    "                xxb.requires_grad_(True)\n",
    "                xb = [xxb,xh]\n",
    "            else:\n",
    "                xb = x_batch.to(device)\n",
    "                xb.requires_grad_(True)\n",
    "            outputs,total_losses = get_loss(model, xb,y_batch)\n",
    "            total_losses.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += total_losses.item()\n",
    "            print('curr loss',total_losses.item(), 'step',i,' | ',end='\\r')\n",
    "            count += 1\n",
    "            with torch.no_grad():\n",
    "                for i,(y,ypred) in enumerate(zip(y_batch,outputs)):\n",
    "                    accuracy = Utils.categorical_accuracy(ypred.float(),format_y(y))\n",
    "                    running_accuracy[i] += accuracy.item()\n",
    "        return running_loss/count, [a/count for a in running_accuracy]\n",
    "    \n",
    "    def val_epoch():\n",
    "        running_loss = 0\n",
    "        running_accuracy = [0,0,0]\n",
    "        running_f1 = [0,0,0]\n",
    "        count = 0\n",
    "        for i, [x_batch, y_batch] in enumerate(validation_loader):\n",
    "            if histogram:\n",
    "                xb = add_batch_histogram(x_batch,device=device,grad=False)\n",
    "            else:\n",
    "                xb = x_batch.to(device)\n",
    "            outputs = model(xb)\n",
    "            outputs,total_losses = get_loss(model,xb,y_batch)\n",
    "            running_loss += total_losses.item()\n",
    "            count += 1\n",
    "            for i,(y,ypred) in enumerate(zip(y_batch, outputs)):\n",
    "                accuracy = Utils.categorical_accuracy(ypred.float(),format_y(y))\n",
    "                f1, precision, recall = Utils.macro_f1(torch.argmax(ypred.float(),axis=1),format_y(y))\n",
    "                running_f1[i] += f1.item()\n",
    "                running_accuracy[i] += accuracy.item()\n",
    "        return running_loss/count, [a/count for a in running_accuracy], [f/count for f in running_f1]\n",
    "    \n",
    "    \n",
    "    best_val_loss = 100000\n",
    "    steps_since_improvement = 0\n",
    "    hist = []\n",
    "    best_weights = model.state_dict()\n",
    "    print('model being saved to',save_path)\n",
    "    for epoch in range(epochs):\n",
    "        print('epoch',epoch)\n",
    "        model.train(True)\n",
    "        avg_loss, avg_acc = train_epoch()\n",
    "        print('train loss', avg_loss, 'train accuracy', avg_acc)\n",
    "        model.eval()\n",
    "        val_loss, val_acc, val_f1 = val_epoch()\n",
    "        print('val loss', val_loss, 'val accuracy', val_acc, 'val f1',val_f1)\n",
    "#         torch.save(model.state_dict(), save_path + '_epoch' + str(epoch))\n",
    "        if best_val_loss > val_loss:\n",
    "            best_weights = copy.deepcopy(model.state_dict())\n",
    "            best_val_loss = val_loss\n",
    "            steps_since_improvement = 0\n",
    "            if epoch > 1:\n",
    "                torch.save(model,save_path)\n",
    "                torch.save(model.state_dict(),save_path+'_states')\n",
    "        else:\n",
    "            steps_since_improvement += 1\n",
    "        \n",
    "        hist_entry = {\n",
    "            'epoch': epoch,\n",
    "            'train_loss': avg_loss,\n",
    "            'train_acc':avg_acc,\n",
    "            'val_loss':val_loss,\n",
    "            'val_acc': val_acc,\n",
    "            'lr': lr,\n",
    "            'loss_weights': '_'.join([str(l) for l in loss_weights])\n",
    "        }\n",
    "        hist.append(hist_entry)\n",
    "        save_train_history(model,hist,root=root)\n",
    "        if steps_since_improvement > patience:\n",
    "            break\n",
    "    return model,hist,best_val_loss\n",
    "\n",
    "\n",
    "# models= [\n",
    "#     TripletModel(encoder=TripletFacenetEncoder(base_model=ResNet18(),base_name='resnetbase',embedding_dropout=.1)),\n",
    "#     TripletModel(encoder=TripletFacenetEncoder(base_model=ResNet18(),base_name='resnetbase',embedding_dropout=.5)),\n",
    "#     TripletModel(encoder=TripletFacenetEncoder(base_model=DenseNet(),base_name='densenetbase',embedding_dropout=.5)),\n",
    "#     TripletModel(encoder=TripletFacenetEncoder(base_model=MobileNet(),base_name='mobilenetbase',embedding_dropout=.5)),\n",
    "#     TripletModel(encoder=TripletFacenetEncoder(base_name='facenetbase',embedding_dropout=.5)),\n",
    "# ]\n",
    "\n",
    "def get_model(file,model=None):\n",
    "    if model is None:\n",
    "        model = torch.load(Constants.model_folder + file).to(torch.device('cpu'))\n",
    "    model.load_state_dict(torch.load(Constants.model_folder + file + '_states'))\n",
    "    model.eval()\n",
    "    return model\n",
    "pretrain_files = [\n",
    "    'dualencoder_resnetbase_h400_ed3triplet_decoder__st600_a400_g400_std2_ad2_gd2_rbalanced_pretrain',\n",
    "    'dualencoder_resnetbase_h400_ed5triplet_decoder__st600_a400_g400_std2_ad2_gd2_rbalanced_pretrain',\n",
    "    'dualencoder_densenetbase_h400_ed5triplet_decoder__st600_a400_g400_std2_ad2_gd2_rbalanced_pretrain',\n",
    "    'dualencoder_mobilenetbase_h400_ed5triplet_decoder__st600_a400_g400_std2_ad2_gd2_rbalanced_pretrain',\n",
    "    'dualencoder_dualfacenet_h400_ed5triplet_decoder__st600_a400_g400_std2_ad2_gd2_rbalanced_pretrain',\n",
    "    'dualencoder_resent_flat_h400_ed5triplet_decoder__st600_a400_g400_std2_ad2_gd2_rbalanced_pretrain',\n",
    "    'dualencoder_resnet_flatbias_h400_ed5triplet_decoder__st600_a400_g400_std2_ad2_gd2_pretrain'\n",
    "]\n",
    "models = [get_model(file) for file in pretrain_files]\n",
    "\n",
    "res = []\n",
    "for model in models:\n",
    "    batch_size=50\n",
    "    if 'densenet' in model.get_identifier():\n",
    "        batch_size=5\n",
    "    m,h,v = train_model(\n",
    "        model,\n",
    "        train_labels,\n",
    "        validation_labels,\n",
    "        Constants.data_root,\n",
    "        batch_size=batch_size,\n",
    "        lr=.0001,\n",
    "    )\n",
    "    entry = (m.get_identifier(),v)\n",
    "    print('________________________________')\n",
    "    print(entry)\n",
    "    print('_______________________________')\n",
    "    res.append(entry)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0f5564",
   "metadata": {},
   "outputs": [],
   "source": [
    "umodels= [\n",
    "    TripletModel(encoder=TripletFacenetEncoder(base_model=ResNet18(),base_name='resnetuntrained',embedding_dropout=.1)),\n",
    "    TripletModel(encoder=TripletFacenetEncoder(base_model=ResNet18(),base_name='resnetuntrained',embedding_dropout=.5)),\n",
    "    TripletModel(encoder=TripletFacenetEncoder(base_model=ResNet18(),base_name='resnetuntrained',embedding_dropout=.7)),\n",
    "    TripletModel(encoder=TripletFacenetEncoder(base_model=MobileNet(),base_name='mobilenetuntrained',embedding_dropout=.5)),\n",
    "    TripletModel(encoder=TripletFacenetEncoder(base_name='facenetuntrained',embedding_dropout=.5)),\n",
    "]\n",
    "\n",
    "for model in umodels:\n",
    "    batch_size=50\n",
    "    m,h,v = train_model(\n",
    "        model,\n",
    "        train_labels,\n",
    "        validation_labels,\n",
    "        Constants.data_root,\n",
    "        batch_size=batch_size,\n",
    "        lr=.0001,\n",
    "    )\n",
    "    entry = (m.get_identifier(),v)\n",
    "    print('________________________________')\n",
    "    print(entry)\n",
    "    print('_______________________________')\n",
    "    res.append(entry)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30424a60-e49f-43d8-8b19-e711c7c82754",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3470cf72-d79e-4449-8b77-340620ba6895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
